import cv2
import pickle
import os
import numpy as np

class FaceRecognitionSystem:
    def __init__(self):
        self.known_face_features = []
        self.known_face_names = []
        self.data_file = "face_data.pkl"
        
        # OpenCV –Ω“Ø“Ø—Ä –æ–ª–æ—Ö classifier
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
        
    def extract_face_features(self, image, face_rect):
        """–ù“Ø“Ø—Ä–Ω–∏–π –æ–Ω—Ü–ª–æ–≥ —à–∏–Ω–∂ —á–∞–Ω–∞—Ä—É—É–¥—ã–≥ –≥–∞—Ä–≥–∞–∂ –∞–≤–∞—Ö"""
        x, y, w, h = face_rect
        face = image[y:y+h, x:x+w]
        
        # –ù“Ø“Ø—Ä–∏–π–≥ —Ç–æ–≥—Ç–º–æ–ª —Ö—ç–º–∂—ç—ç –±–æ–ª–≥–æ—Ö
        face_resized = cv2.resize(face, (100, 100))
        
        # Gray scale –±–æ–ª–≥–æ—Ö
        gray_face = cv2.cvtColor(face_resized, cv2.COLOR_BGR2GRAY)
        
        # Histogram –∞—à–∏–≥–ª–∞—Ö (—ç–Ω–≥–∏–π–Ω feature vector)
        hist = cv2.calcHist([gray_face], [0], None, [256], [0, 256])
        hist = cv2.normalize(hist, hist).flatten()
        
        # LBP (Local Binary Pattern) —Ö–∏–π—Ö - –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª —Å–∞–π–∂—Ä—É—É–ª–∞—Ö
        lbp_features = self.compute_lbp(gray_face)
        
        # –•–æ—ë—Ä—ã–≥ –Ω—ç–≥—Ç–≥—ç—Ö
        features = np.concatenate([hist, lbp_features])
        
        return features
    
    def compute_lbp(self, image):
        """Local Binary Pattern features"""
        height, width = image.shape
        lbp = np.zeros((height-2, width-2), dtype=np.uint8)
        
        for i in range(1, height-1):
            for j in range(1, width-1):
                center = image[i, j]
                code = 0
                code |= (image[i-1, j-1] >= center) << 7
                code |= (image[i-1, j] >= center) << 6
                code |= (image[i-1, j+1] >= center) << 5
                code |= (image[i, j+1] >= center) << 4
                code |= (image[i+1, j+1] >= center) << 3
                code |= (image[i+1, j] >= center) << 2
                code |= (image[i+1, j-1] >= center) << 1
                code |= (image[i, j-1] >= center) << 0
                lbp[i-1, j-1] = code
        
        # LBP histogram
        hist_lbp = cv2.calcHist([lbp], [0], None, [256], [0, 256])
        hist_lbp = cv2.normalize(hist_lbp, hist_lbp).flatten()
        
        return hist_lbp
    
    # 1. –î–ê–¢–ê–ì –¶–£–ì–õ–£–£–õ–ê–• - –ó—É—Ä–∞–≥ —ç—Å–≤—ç–ª –≤–µ–±–∫–∞–º–∞–∞—Å
    def collect_face_data_from_images(self, images_folder):
        """–ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä–æ–æ—Å –Ω“Ø“Ø—Ä–∏–π–≥ —Ç–∞–Ω–∏—É–ª–∞—Ö"""
        print("üì∏ –ó—É—Ä–≥–∞–∞—Å –Ω“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∂ –±–∞–π–Ω–∞...")
        
        for filename in os.listdir(images_folder):
            if filename.endswith((".jpg", ".jpeg", ".png")):
                image_path = os.path.join(images_folder, filename)
                image = cv2.imread(image_path)
                
                if image is None:
                    print(f"‚ùå {filename} —É–Ω—à–∏–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π")
                    continue
                
                # –ù“Ø“Ø—Ä –æ–ª–æ—Ö
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
                
                if len(faces) > 0:
                    # –•–∞–º–≥–∏–π–Ω —Ç–æ–º –Ω“Ø“Ø—Ä–∏–π–≥ –∞–≤–∞—Ö
                    face = max(faces, key=lambda rect: rect[2] * rect[3])
                    features = self.extract_face_features(image, face)
                    
                    # –§–∞–π–ª—ã–Ω –Ω—ç—Ä–∏–π–≥ —Ö“Ø–Ω–∏–π –Ω—ç—Ä –±–æ–ª–≥–æ—Ö
                    name = os.path.splitext(filename)[0]
                    self.known_face_features.append(features)
                    self.known_face_names.append(name)
                    print(f"‚úÖ {name} —Ç–∞–Ω–∏—É–ª—Å–∞–Ω")
                else:
                    print(f"‚ùå {filename}-–¥ –Ω“Ø“Ø—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π")
    
    def collect_face_data_from_webcam(self, name, num_samples=5):
        """–í–µ–±–∫–∞–º–∞–∞—Å –Ω“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∞—Ö"""
        print(f"üìπ {name}-—ã–Ω –Ω“Ø“Ø—Ä–∏–π–≥ {num_samples} —É–¥–∞–∞ –∞–≤–∞—Ö –≥—ç–∂ –±–∞–π–Ω–∞...")
        print("–ö–∞–º–µ—Ä –Ω—ç—ç–≥–¥—ç—Ö –±–æ–ª–Ω–æ. 'Space' –¥–∞—Ä–∂ –∑—É—Ä–∞–≥ –∞–≤–Ω–∞ —É—É!")
        
        video_capture = cv2.VideoCapture(0)
        features_list = []
        count = 0
        
        while count < num_samples:
            ret, frame = video_capture.read()
            if not ret:
                break
            
            # –ù“Ø“Ø—Ä –æ–ª–æ—Ö
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
            
            # –ù“Ø“Ø—Ä“Ø“Ø–¥–∏–π–≥ –∑—É—Ä–∞—Ö
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                
                # –ù“Ø–¥–∏–π–≥ –æ–ª–æ—Ö (–Ω–∞—Ä–∏–π–≤—á–ª–∞–ª —Å–∞–π–∂—Ä—É—É–ª–∞—Ö)
                roi_gray = gray[y:y+h, x:x+w]
                eyes = self.eye_cascade.detectMultiScale(roi_gray)
                for (ex, ey, ew, eh) in eyes:
                    cv2.rectangle(frame, (x+ex, y+ey), (x+ex+ew, y+ey+eh), (255, 0, 0), 2)
            
            # –ú—ç–¥—ç—ç–ª—ç–ª —Ö–∞—Ä—É—É–ª–∞—Ö
            cv2.putText(frame, f"–ê–≤—Å–∞–Ω: {count}/{num_samples}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, "Space - –∑—É—Ä–∞–≥ –∞–≤–∞—Ö, Q - –≥–∞—Ä–∞—Ö", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            if len(faces) > 0:
                cv2.putText(frame, "–ù“Ø“Ø—Ä –æ–ª–¥–ª–æ–æ! Space –¥–∞—Ä–Ω–∞ —É—É", (10, 90),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—É–ª–∞—Ö', frame)
            
            key = cv2.waitKey(1) & 0xFF
            
            # Space –¥–∞—Ä–∞—Ö–∞–¥ –∑—É—Ä–∞–≥ –∞–≤–∞—Ö
            if key == ord(' ') and len(faces) > 0:
                # –•–∞–º–≥–∏–π–Ω —Ç–æ–º –Ω“Ø“Ø—Ä–∏–π–≥ –∞–≤–∞—Ö
                face = max(faces, key=lambda rect: rect[2] * rect[3])
                features = self.extract_face_features(frame, face)
                features_list.append(features)
                count += 1
                print(f"‚úÖ –ó—É—Ä–∞–≥ {count} –∞–≤–ª–∞–∞!")
            
            # Q –¥–∞—Ä–∞—Ö–∞–¥ –≥–∞—Ä–∞—Ö
            elif key == ord('q'):
                break
        
        video_capture.release()
        cv2.destroyAllWindows()
        
        # –î—É–Ω–¥–∞–∂ features –∞–≤–∞—Ö
        if features_list:
            avg_features = np.mean(features_list, axis=0)
            self.known_face_features.append(avg_features)
            self.known_face_names.append(name)
            print(f"‚úÖ {name} –∞–º–∂–∏–ª—Ç—Ç–∞–π —Ç–∞–Ω–∏—É–ª—Å–∞–Ω!")
            return True
        else:
            print(f"‚ùå –ù“Ø“Ø—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False
    
    # 2. –î–ê–¢–ê–ì –•–ê–î–ì–ê–õ–ê–•
    def save_data(self):
        """–ù“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞–≥ —Ñ–∞–π–ª–¥ —Ö–∞–¥–≥–∞–ª–∞—Ö"""
        data = {
            'features': self.known_face_features,
            'names': self.known_face_names
        }
        with open(self.data_file, 'wb') as f:
            pickle.dump(data, f)
        print(f"üíæ –î–∞—Ç–∞ {self.data_file} —Ñ–∞–π–ª–¥ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞!")
    
    # 3. –î–ê–¢–ê–ì –£–ù–®–ò–ñ –ê–ß–ê–ê–õ–ê–•
    def load_data(self):
        """–•–∞–¥–≥–∞–ª—Å–∞–Ω –¥–∞—Ç–∞–≥ –∞—á–∞–∞–ª–∞—Ö"""
        if os.path.exists(self.data_file):
            with open(self.data_file, 'rb') as f:
                data = pickle.load(f)
                self.known_face_features = data['features']
                self.known_face_names = data['names']
            print(f"‚úÖ {len(self.known_face_names)} —Ö“Ø–Ω–∏–π –¥–∞—Ç–∞ –∞—á–∞–∞–ª–∞–≥–¥–ª–∞–∞!")
            print(f"–•“Ø–º“Ø“Ø—Å: {', '.join(self.known_face_names)}")
            return True
        else:
            print(f"‚ùå {self.data_file} —Ñ–∞–π–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False
    
    def compare_faces(self, features1, features2):
        """–•–æ—ë—Ä –Ω“Ø“Ø—Ä–∏–π–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö"""
        # Cosine similarity –∞—à–∏–≥–ª–∞—Ö
        similarity = np.dot(features1, features2) / (np.linalg.norm(features1) * np.linalg.norm(features2))
        # Similarity –∏—Ö –±–∞–π—Ö —Ç—É—Å–∞–º –Ω“Ø“Ø—Ä –∏–∂–∏–ª (0-1 —Ö–æ–æ—Ä–æ–Ω–¥)
        return similarity, similarity > 0.85  # Threshold: 0.85
    
    # 4. –í–ò–î–ï–û–ì–û–û–† –¢–ê–ù–ò–õ–¢ –•–ò–ô–•
    def recognize_faces_video(self):
        """–í–∏–¥–µ–æ–≥–æ–æ—Ä –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö"""
        if not self.known_face_features:
            print("‚ùå –≠—Ö–ª—ç—ç–¥ –¥–∞—Ç–∞ –∞—á–∞–∞–ª–Ω–∞ —É—É!")
            return
        
        print("üé• –ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º —ç—Ö—ç–ª–ª—ç—ç...")
        print("Q –¥–∞—Ä–∂ –≥–∞—Ä–Ω–∞ —É—É!")
        
        video_capture = cv2.VideoCapture(0)
        frame_count = 0
        
        while True:
            ret, frame = video_capture.read()
            if not ret:
                break
            
            frame_count += 1
            
            # –•—É—Ä–¥—ã–≥ —Å–∞–π–∂—Ä—É—É–ª–∞—Ö—ã–Ω —Ç—É–ª–¥ 3 frame —Ç—É—Ç–∞–º–¥ —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö
            if frame_count % 3 != 0:
                cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
                continue
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
            
            for (x, y, w, h) in faces:
                # –ù“Ø“Ø—Ä–Ω–∏–π features –≥–∞—Ä–≥–∞—Ö
                features = self.extract_face_features(frame, (x, y, w, h))
                
                name = "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π"
                confidence = 0
                
                # –ë“Ø—Ö —Ç–∞–Ω–∏—É–ª—Å–∞–Ω –Ω“Ø“Ø—Ä—Ç—ç–π —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö
                max_similarity = 0
                best_match_idx = -1
                
                for idx, known_features in enumerate(self.known_face_features):
                    similarity, is_match = self.compare_faces(known_features, features)
                    if similarity > max_similarity:
                        max_similarity = similarity
                        best_match_idx = idx
                
                # Threshold —à–∞–ª–≥–∞—Ö
                if max_similarity > 0.85:  # –≠–Ω—ç —É—Ç–≥—ã–≥ —Ç–æ—Ö–∏—Ä—É—É–ª–∂ –±–æ–ª–Ω–æ
                    name = self.known_face_names[best_match_idx]
                    confidence = max_similarity * 100
                
                # –•“Ø—Ä—ç—ç –∑—É—Ä–∞—Ö
                color = (0, 255, 0) if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π" else (0, 0, 255)
                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                
                # –ù—ç—Ä–Ω–∏–π ”©–Ω–≥”©—Ç—ç–π –¥—ç–≤—Å–≥—ç—Ä –∑—É—Ä–∞—Ö
                cv2.rectangle(frame, (x, y-35), (x+w, y), color, cv2.FILLED)
                
                # –ù—ç—Ä –±–∏—á–∏—Ö
                text = f"{name} ({confidence:.1f}%)" if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π" else name
                cv2.putText(frame, text, (x + 6, y - 6),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º', frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        video_capture.release()
        cv2.destroyAllWindows()

# ================ –•–≠–†–≠–ì–õ–≠–• –ñ–ò–®–≠–≠ ================

if __name__ == "__main__":
    system = FaceRecognitionSystem()
    
    print("üéØ –ù“Æ“Æ–† –¢–ê–ù–ò–• –°–ò–°–¢–ï–ú (OpenCV Haar Cascade)")
    print("=" * 50)
    print("1 - –í–µ–±–∫–∞–º–∞–∞—Å –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∞—Ö")
    print("2 - –ó—É—Ä–≥–∞–∞—Å –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∞—Ö")
    print("3 - –î–∞—Ç–∞–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö")
    print("4 - –î–∞—Ç–∞–≥ –∞—á–∞–∞–ª–∞—Ö")
    print("5 - –í–∏–¥–µ–æ–≥–æ–æ—Ä —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö")
    print("0 - –ì–∞—Ä–∞—Ö")
    print("=" * 50)
    
    while True:
        choice = input("\n–°–æ–Ω–≥–æ–ª—Ç –æ—Ä—É—É–ª–Ω–∞ —É—É: ")
        
        if choice == '1':
            name = input("–•“Ø–Ω–∏–π –Ω—ç—Ä: ")
            num = int(input("–•—ç–¥—ç–Ω –∑—É—Ä–∞–≥ –∞–≤–∞—Ö –≤—ç? (5-10 —Å–∞–Ω–∞–ª –±–æ–ª–≥–æ—Ö): "))
            system.collect_face_data_from_webcam(name, num)
            
        elif choice == '2':
            folder = input("–ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä: ")
            if os.path.exists(folder):
                system.collect_face_data_from_images(folder)
            else:
                print("‚ùå –§–æ–ª–¥–µ—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
                
        elif choice == '3':
            system.save_data()
            
        elif choice == '4':
            system.load_data()
            
        elif choice == '5':
            system.recognize_faces_video()
            
        elif choice == '0':
            print("üëã –ë–∞—è—Ä—Ç–∞–π!")
            break
        else:
            print("‚ùå –ë—É—Ä—É—É —Å–æ–Ω–≥–æ–ª—Ç!")