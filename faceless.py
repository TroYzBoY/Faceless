import cv2
import pickle
import os
import numpy as np
from datetime import datetime
import time


class FaceRecognitionSystem:
    def __init__(self, threshold=0.82, data_file="face_data.pkl"):
        self.known_face_features = []
        self.known_face_names = []
        self.data_file = data_file  # –û–¥–æ–æ ”©”©—Ä—á–ª”©—Ö –±–æ–ª–æ–º–∂—Ç–æ–π
        self.threshold = threshold

        # OpenCV –Ω“Ø“Ø—Ä –æ–ª–æ—Ö classifier
        cascade_path = cv2.data.haarcascades
        self.face_cascade = cv2.CascadeClassifier(
            cascade_path + 'haarcascade_frontalface_default.xml')
        self.eye_cascade = cv2.CascadeClassifier(
            cascade_path + 'haarcascade_eye.xml')

        if self.face_cascade.empty() or self.eye_cascade.empty():
            raise Exception("‚ùå Haar Cascade —Ñ–∞–π–ª—É—É–¥ –∞—á–∞–∞–ª–∞–≥–¥—Å–∞–Ω–≥“Ø–π!")

    def extract_face_features(self, image, face_rect):
        """–ù“Ø“Ø—Ä–Ω–∏–π –æ–Ω—Ü–ª–æ–≥ —à–∏–Ω–∂ —á–∞–Ω–∞—Ä—É—É–¥—ã–≥ –≥–∞—Ä–≥–∞–∂ –∞–≤–∞—Ö"""
        try:
            x, y, w, h = face_rect

            if x < 0 or y < 0 or x+w > image.shape[1] or y+h > image.shape[0]:
                return None

            face = image[y:y+h, x:x+w]

            if face.size == 0:
                return None

            face_resized = cv2.resize(face, (100, 100))

            if len(face_resized.shape) == 3:
                gray_face = cv2.cvtColor(face_resized, cv2.COLOR_BGR2GRAY)
            else:
                gray_face = face_resized

            gray_face = cv2.equalizeHist(gray_face)

            hist = cv2.calcHist([gray_face], [0], None, [256], [0, 256])
            hist = cv2.normalize(hist, hist).flatten()

            lbp_features = self.compute_lbp(gray_face)
            hog_features = self.compute_hog(gray_face)

            features = np.concatenate([hist, lbp_features, hog_features])

            return features
        except Exception as e:
            return None

    def compute_lbp(self, image):
        """Local Binary Pattern features"""
        height, width = image.shape
        radius = 1
        lbp = np.zeros((height-2*radius, width-2*radius), dtype=np.uint8)

        for i in range(radius, height-radius):
            for j in range(radius, width-radius):
                center = image[i, j]
                code = 0
                code |= (image[i-1, j-1] >= center) << 7
                code |= (image[i-1, j] >= center) << 6
                code |= (image[i-1, j+1] >= center) << 5
                code |= (image[i, j+1] >= center) << 4
                code |= (image[i+1, j+1] >= center) << 3
                code |= (image[i+1, j] >= center) << 2
                code |= (image[i+1, j-1] >= center) << 1
                code |= (image[i, j-1] >= center) << 0
                lbp[i-radius, j-radius] = code

        hist_lbp = cv2.calcHist([lbp], [0], None, [256], [0, 256])
        hist_lbp = cv2.normalize(hist_lbp, hist_lbp).flatten()

        return hist_lbp

    def compute_hog(self, image):
        """HOG (Histogram of Oriented Gradients) features"""
        gx = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=1)
        gy = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=1)

        mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)

        bins = np.int32(angle / 40)
        bin_cells = []

        cell_size = 10
        for i in range(0, image.shape[0] - cell_size, cell_size):
            for j in range(0, image.shape[1] - cell_size, cell_size):
                cell_mag = mag[i:i+cell_size, j:j+cell_size]
                cell_angle = bins[i:i+cell_size, j:j+cell_size]

                hist = np.zeros(9)
                for k in range(9):
                    hist[k] = np.sum(cell_mag[cell_angle == k])

                bin_cells.extend(hist)

        hog_features = np.array(bin_cells)
        if np.linalg.norm(hog_features) > 0:
            hog_features = hog_features / np.linalg.norm(hog_features)

        return hog_features[:256]

    def auto_collect_face_data(self, name, num_samples=10, auto_save=True):
        """
        ü§ñ –ê–í–¢–û–ú–ê–¢ –ù“Æ“Æ–† –¢–ê–ù–ò–£–õ–ê–• - Phone Face ID —à–∏–≥
        –ê–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –Ω“Ø“Ø—Ä–∏–π–≥ –æ–ª–∂, –∑—É—Ä–∞–≥ –∞–≤–∞–∞–¥, —Ö–∞–¥–≥–∞–ª–Ω–∞
        """
        print(f"\n{'='*60}")
        print(f"üì± {name}-—ã–Ω –Ω“Ø“Ø—Ä–∏–π–≥ –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –±“Ø—Ä—Ç–≥—ç–∂ –±–∞–π–Ω–∞...")
        print(f"üéØ {num_samples} ”©”©—Ä ”©–Ω—Ü–≥”©”©—Å –∑—É—Ä–∞–≥ –∞–≤–Ω–∞")
        print(f"üí° –¢–æ–ª–≥–æ–π–≥–æ–æ –∞–∞–∂—É—É—Ö–∞–Ω —ç—Ä–≥“Ø“Ø–ª—ç—ç—Ä—ç–π")
        print(f"{'='*60}\n")

        video_capture = cv2.VideoCapture(0)

        if not video_capture.isOpened():
            print("‚ùå –ö–∞–º–µ—Ä –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
            return False

        features_list = []
        count = 0
        last_capture_time = time.time()
        capture_interval = 0.5

        face_positions = []
        min_position_diff = 20

        stable_frames = 0
        min_stable_frames = 3  # –ë–∞–≥–∞—Å–≥–∞—Å–∞–Ω - —Ö—É—Ä–¥–∞–Ω –±–æ–ª–≥–æ—Ö

        print("üîç –ù“Ø“Ø—Ä–∏–π–≥ –æ–ª–∂ –±–∞–π–Ω–∞...")

        while count < num_samples:
            ret, frame = video_capture.read()
            if not ret:
                print("‚ùå –ö–∞–º–µ—Ä–∞–∞—Å frame —É–Ω—à–∏–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π!")
                break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.1, minNeighbors=5,
                minSize=(100, 100), maxSize=(400, 400)
            )

            current_time = time.time()
            face_detected = False
            ready_to_capture = False

            for (x, y, w, h) in faces:
                face_detected = True

                roi_gray = gray[y:y+h, x:x+w]
                eyes = self.eye_cascade.detectMultiScale(
                    roi_gray, minNeighbors=8)

                has_eyes = len(eyes) >= 2

                face_center = (x + w//2, y + h//2)

                is_new_angle = True
                for prev_pos in face_positions:
                    distance = np.sqrt((face_center[0] - prev_pos[0])**2 +
                                       (face_center[1] - prev_pos[1])**2)
                    if distance < min_position_diff:
                        is_new_angle = False
                        break

                if has_eyes and is_new_angle:
                    color = (0, 255, 0)
                    stable_frames += 1
                    ready_to_capture = stable_frames >= min_stable_frames
                elif has_eyes:
                    color = (0, 255, 255)
                    stable_frames = 0
                else:
                    color = (0, 165, 255)
                    stable_frames = 0

                thickness = 3 if ready_to_capture else 2
                cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness)

                for (ex, ey, ew, eh) in eyes:
                    cv2.circle(frame, (x+ex+ew//2, y+ey+eh//2),
                               ew//2, (255, 0, 0), 2)

                if (ready_to_capture and
                    is_new_angle and
                    has_eyes and
                        current_time - last_capture_time >= capture_interval):

                    features = self.extract_face_features(frame, (x, y, w, h))

                    if features is not None:
                        features_list.append(features)
                        face_positions.append(face_center)
                        count += 1
                        last_capture_time = current_time
                        stable_frames = 0

                        cv2.circle(frame, (frame.shape[1]//2, frame.shape[0]//2),
                                   50, (0, 255, 0), 5)

                        print(f"üì∏ {count}/{num_samples} - ‚úì –ê–≤–ª–∞–∞!")

            bar_width = frame.shape[1] - 40
            bar_height = 30
            bar_x, bar_y = 20, frame.shape[0] - 50

            cv2.rectangle(frame, (bar_x-5, bar_y-5),
                          (bar_x + bar_width + 5, bar_y + bar_height + 5),
                          (50, 50, 50), cv2.FILLED)

            progress = int((count / num_samples) * bar_width)
            cv2.rectangle(frame, (bar_x, bar_y),
                          (bar_x + progress, bar_y + bar_height),
                          (0, 255, 0), cv2.FILLED)

            progress_text = f"{count}/{num_samples}"
            cv2.putText(frame, progress_text,
                        (bar_x + bar_width//2 - 30, bar_y + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            if face_detected:
                if ready_to_capture:
                    status = "üì∏ –ê–≤—á –±–∞–π–Ω–∞..."
                    color = (0, 255, 0)
                elif not has_eyes:
                    status = "üëÄ –ù“Ø–¥–∏–π–≥ —Ö–∞—Ä—É—É–ª–Ω–∞ —É—É"
                    color = (0, 165, 255)
                elif not is_new_angle:
                    status = "üîÑ –¢–æ–ª–≥–æ–π–≥–æ–æ —ç—Ä–≥“Ø“Ø–ª–Ω—ç “Ø“Ø"
                    color = (0, 255, 255)
                else:
                    status = "‚è≥ –ë—ç–ª–¥—ç–∂ –±–∞–π–Ω–∞..."
                    color = (255, 255, 0)
            else:
                status = "üîç –ù“Ø“Ø—Ä–∏–π–≥ –æ–ª–∂ –±–∞–π–Ω–∞..."
                color = (0, 0, 255)

            cv2.putText(frame, status, (20, 40),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

            instruction = "Q - —Ü—É—Ü–ª–∞—Ö | –ê–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –∞–≤–Ω–∞"
            cv2.putText(frame, instruction, (20, 75),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            cv2.imshow('Auto Face ID', frame)

            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\nüö´ –•—ç—Ä—ç–≥–ª—ç–≥—á —Ü—É—Ü–∞–ª—Å–∞–Ω")
                break

        video_capture.release()
        cv2.destroyAllWindows()

        if len(features_list) >= 3:
            # –•–£–£–ß–ò–Ω –ö–û–î: –∑”©–≤—Ö”©–Ω –¥—É–Ω–¥–∞–∂ feature —Ö–∞–¥–≥–∞–ª–∂ –±–∞–π—Å–∞–Ω
            # avg_features = np.mean(features_list, axis=0)
            # self.known_face_features.append(avg_features)
            # self.known_face_names.append(name)

            # –®–ò–ù–≠ –ö–û–î: –ë“Ø—Ö features-–∏–π–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö (–∏–ª“Ø“Ø —Å–∞–π–Ω —Ç–∞–Ω–∏–ª—Ç)
            for features in features_list:
                self.known_face_features.append(features)
                self.known_face_names.append(name)

            print(f"\n{'='*60}")
            print(f"‚úÖ {name} –∞–º–∂–∏–ª—Ç—Ç–∞–π –±“Ø—Ä—Ç–≥—ç–≥–¥–ª—ç—ç!")
            print(f"üìä {len(features_list)} –∑—É—Ä–∞–≥ —Ö–∞–¥–≥–∞–ª—Å–∞–Ω")
            print(f"{'='*60}\n")

            if auto_save:
                self.save_data()

            return True
        else:
            print(
                f"\n‚ùå –•–∞–Ω–≥–∞–ª—Ç—Ç–∞–π –∑—É—Ä–∞–≥ –∞–≤–∞–∞–≥“Ø–π! ({len(features_list)}/{num_samples})")
            return False

    def collect_face_data_from_images(self, images_folder):
        """–ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä–æ–æ—Å –Ω“Ø“Ø—Ä–∏–π–≥ —Ç–∞–Ω–∏—É–ª–∞—Ö"""
        print(f"üì∏ {images_folder}-–æ–æ—Å –Ω“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∂ –±–∞–π–Ω–∞...")

        if not os.path.exists(images_folder):
            print(f"‚ùå {images_folder} –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return

        image_files = [f for f in os.listdir(images_folder)
                       if f.lower().endswith((".jpg", ".jpeg", ".png", ".bmp"))]

        if not image_files:
            print("‚ùå –ó—É—Ä–∞–≥ –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return

        success_count = 0
        for filename in image_files:
            image_path = os.path.join(images_folder, filename)
            image = cv2.imread(image_path)

            if image is None:
                print(f"‚ö†Ô∏è {filename} —É–Ω—à–∏–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π")
                continue

            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.1, minNeighbors=5,
                minSize=(50, 50), maxSize=(500, 500)
            )

            if len(faces) > 0:
                face = max(faces, key=lambda rect: rect[2] * rect[3])
                features = self.extract_face_features(image, face)

                if features is not None:
                    name = os.path.splitext(
                        filename)[0].replace('_', ' ').title()
                    self.known_face_features.append(features)
                    self.known_face_names.append(name)
                    success_count += 1
                    print(f"‚úÖ {name} —Ç–∞–Ω–∏—É–ª—Å–∞–Ω")
                else:
                    print(f"‚ö†Ô∏è {filename}-–Ω features –≥–∞—Ä–≥–∞–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π")
            else:
                print(f"‚ö†Ô∏è {filename}-–¥ –Ω“Ø“Ø—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π")

        print(f"\nüìä –ù–∏–π—Ç: {success_count}/{len(image_files)} –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏—É–ª—Å–∞–Ω")

    def save_data(self):
        """–ù“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞–≥ —Ñ–∞–π–ª–¥ —Ö–∞–¥–≥–∞–ª–∞—Ö"""
        try:
            data = {
                'features': self.known_face_features,
                'names': self.known_face_names,
                'threshold': self.threshold,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            with open(self.data_file, 'wb') as f:
                pickle.dump(data, f)

            from collections import Counter
            name_counts = Counter(self.known_face_names)

            print(f"üíæ –î–∞—Ç–∞ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞!")
            print(f"üìÅ –§–∞–π–ª: {self.data_file}")
            print(f"üë• –•“Ø–º“Ø“Ø—Å: {len(name_counts)}")
            print(f"üìä –ù–∏–π—Ç –∑—É—Ä–∞–≥: {len(self.known_face_names)}")
        except Exception as e:
            print(f"‚ùå –•–∞–¥–≥–∞–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}")

    def load_data(self):
        """–•–∞–¥–≥–∞–ª—Å–∞–Ω –¥–∞—Ç–∞–≥ –∞—á–∞–∞–ª–∞—Ö"""
        if not os.path.exists(self.data_file):
            print(f"‚ùå {self.data_file} —Ñ–∞–π–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False

        try:
            with open(self.data_file, 'rb') as f:
                data = pickle.load(f)
                self.known_face_features = data['features']
                self.known_face_names = data['names']

                if 'threshold' in data:
                    self.threshold = data['threshold']

                if 'timestamp' in data:
                    print(f"üìÖ –•–∞–¥–≥–∞–ª—Å–∞–Ω –æ–≥–Ω–æ–æ: {data['timestamp']}")

            from collections import Counter
            name_counts = Counter(self.known_face_names)

            print(f"‚úÖ –î–∞—Ç–∞ –∞—á–∞–∞–ª–∞–≥–¥–ª–∞–∞!")
            print(
                f"üë• –•“Ø–º“Ø“Ø—Å ({len(name_counts)}): {', '.join(sorted(name_counts.keys()))}")
            print(f"üìä –ù–∏–π—Ç –∑—É—Ä–∞–≥: {len(self.known_face_names)}")
            return True
        except Exception as e:
            print(f"‚ùå –ê—á–∞–∞–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}")
            return False

    def compare_faces(self, features1, features2):
        """–•–æ—ë—Ä –Ω“Ø“Ø—Ä–∏–π–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö"""
        cos_sim = np.dot(features1, features2) / (
            np.linalg.norm(features1) * np.linalg.norm(features2) + 1e-6
        )

        euclidean_dist = np.linalg.norm(features1 - features2)
        euclidean_sim = 1 / (1 + euclidean_dist)

        similarity = 0.7 * cos_sim + 0.3 * euclidean_sim
        is_match = similarity > self.threshold

        return similarity, is_match

    def recognize_faces_video(self):
        """–í–∏–¥–µ–æ–≥–æ–æ—Ä –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö - –û–ù–û–í–ß–õ–û–ì–î–°–û–ù"""
        if not self.known_face_features:
            print("‚ùå –≠—Ö–ª—ç—ç–¥ –¥–∞—Ç–∞ –∞—á–∞–∞–ª–Ω–∞ —É—É —ç—Å–≤—ç–ª –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏—É–ª–Ω–∞ —É—É!")
            return

        print(f"\nüé• –ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º —ç—Ö—ç–ª–ª—ç—ç")
        print(f"üë• –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π: {len(set(self.known_face_names))} —Ö“Ø–Ω")
        print(f"üìä –ù–∏–π—Ç –∑—É—Ä–∞–≥: {len(self.known_face_names)}")
        print(f"üéØ Threshold: {self.threshold:.2f}")
        print("Q –¥–∞—Ä–∂ –≥–∞—Ä–Ω–∞ —É—É!\n")

        video_capture = cv2.VideoCapture(0)

        if not video_capture.isOpened():
            print("‚ùå –ö–∞–º–µ—Ä –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
            return

        # –•—É—Ä–¥ —Å–∞–π–∂—Ä—É—É–ª–∞—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä“Ø“Ø–¥
        frame_skip = 3  # 3 frame —Ç—É—Ç–∞–º–¥ —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö
        frame_count = 0

        # FPS —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö
        fps_start_time = time.time()
        fps_frame_count = 0
        fps = 0

        # –°“Ø“Ø–ª–∏–π–Ω —Ç–∞–Ω–∏–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω —Ö–∞–¥–≥–∞–ª–∞—Ö
        last_results = {}

        while True:
            ret, frame = video_capture.read()
            if not ret:
                break

            frame_count += 1
            fps_frame_count += 1

            # FPS —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö
            if fps_frame_count >= 30:
                elapsed = time.time() - fps_start_time
                fps = fps_frame_count / elapsed if elapsed > 0 else 0
                fps_start_time = time.time()
                fps_frame_count = 0

            # Frame skip - —Ö—É—Ä–¥ —Å–∞–π–∂—Ä—É—É–ª–∞—Ö
            if frame_count % frame_skip != 0:
                # –°“Ø“Ø–ª–∏–π–Ω “Ø—Ä –¥“Ø–Ω–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
                for face_id, (x, y, w, h, name, confidence) in last_results.items():
                    if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π":
                        if confidence > 90:
                            color = (0, 255, 0)
                        elif confidence > 85:
                            color = (0, 255, 255)
                        else:
                            color = (0, 165, 255)
                    else:
                        color = (0, 0, 255)

                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)

                    label_y = y - 10 if y - 10 > 10 else y + h + 20
                    cv2.rectangle(frame, (x, label_y - 25),
                                  (x+w, label_y), color, cv2.FILLED)

                    text = f"{name} ({confidence:.0f}%)" if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π" else name
                    cv2.putText(frame, text, (x + 5, label_y - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
                continue

            # –ù“Ø“Ø—Ä –æ–ª–æ—Ö
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.2, minNeighbors=5,
                minSize=(60, 60), maxSize=(400, 400)
            )

            # –®–∏–Ω—ç “Ø—Ä –¥“Ø–Ω —Ö–∞–¥–≥–∞–ª–∞—Ö
            new_results = {}

            for face_id, (x, y, w, h) in enumerate(faces):
                features = self.extract_face_features(frame, (x, y, w, h))

                if features is None:
                    continue

                name = "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π"
                confidence = 0

                max_similarity = 0
                best_match_name = None

                # –ë“Ø—Ö —Ö–∞–¥–≥–∞–ª—Å–∞–Ω features-—Ç–∞–π —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö
                for idx, known_features in enumerate(self.known_face_features):
                    similarity, _ = self.compare_faces(
                        known_features, features)
                    if similarity > max_similarity:
                        max_similarity = similarity
                        best_match_name = self.known_face_names[idx]

                if max_similarity > self.threshold and best_match_name:
                    name = best_match_name
                    confidence = max_similarity * 100

                # “Æ—Ä –¥“Ø–Ω —Ö–∞–¥–≥–∞–ª–∞—Ö
                new_results[face_id] = (x, y, w, h, name, confidence)

                # –•“Ø—Ä—ç—ç –∑—É—Ä–∞—Ö
                if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π":
                    if confidence > 90:
                        color = (0, 255, 0)
                    elif confidence > 85:
                        color = (0, 255, 255)
                    else:
                        color = (0, 165, 255)
                else:
                    color = (0, 0, 255)

                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)

                label_y = y - 10 if y - 10 > 10 else y + h + 20
                cv2.rectangle(frame, (x, label_y - 25),
                              (x+w, label_y), color, cv2.FILLED)

                text = f"{name} ({confidence:.0f}%)" if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π" else name
                cv2.putText(frame, text, (x + 5, label_y - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            # –°“Ø“Ø–ª–∏–π–Ω “Ø—Ä –¥“Ø–Ω–≥ —à–∏–Ω—ç—á–ª—ç—Ö
            last_results = new_results

            # –ú—ç–¥—ç—ç–ª—ç–ª —Ö–∞—Ä—É—É–ª–∞—Ö
            cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            cv2.putText(frame, f"–ù“Ø“Ø—Ä: {len(faces)}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º', frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        video_capture.release()
        cv2.destroyAllWindows()
        print("\nüëã –°–∏—Å—Ç–µ–º —Ö–∞–∞–≥–¥–ª–∞–∞")

    def delete_person(self, name):
        """–•“Ø–Ω–∏–π –¥–∞—Ç–∞–≥ —É—Å—Ç–≥–∞—Ö"""
        indices_to_remove = [i for i, n in enumerate(
            self.known_face_names) if n == name]

        if not indices_to_remove:
            print(f"‚ùå {name} –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False

        for idx in sorted(indices_to_remove, reverse=True):
            del self.known_face_features[idx]
            del self.known_face_names[idx]

        print(f"‚úÖ {name} ({len(indices_to_remove)} –∑—É—Ä–∞–≥) —É—Å—Ç–≥–∞–≥–¥–ª–∞–∞!")
        return True

    def list_people(self):
        """–ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö"""
        if not self.known_face_names:
            print("üìã –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–Ω –±–∞–π—Ö–≥“Ø–π")
            return

        from collections import Counter
        name_counts = Counter(self.known_face_names)

        print(f"\nüìã –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å ({len(name_counts)}):")
        print("=" * 50)
        for name, count in sorted(name_counts.items()):
            print(f"  üë§ {name}: {count} –∑—É—Ä–∞–≥")
        print("=" * 50)


def main():
    # ”®”®–†–ò–ô–ù –ó–ê–ú–ê–ê –≠–ù–î–ï –û–†–£–£–õ–ù–ê –£–£!
    # –ñ–∏—à—ç—ç: data_file="C:/Users/YourName/Desktop/data/face_data.pkl"
    system = FaceRecognitionSystem(threshold=0.82, data_file="C:/Users/troyz/OneDrive/Desktop/faceless/data/face_data.pkl")
    print("=" * 60)
    print("üì± AUTO FACE ID –°–ò–°–¢–ï–ú (Phone Face ID —à–∏–≥)")
    print("=" * 60)
    print(f"üìÅ –î–∞—Ç–∞ —Ñ–∞–π–ª: {system.data_file}\n")

    while True:
        print("\nüìã “Æ–ô–õ –ê–ñ–ò–õ–õ–ê–ì–ê–ê:")
        print("  1 - ü§ñ –ê–í–¢–û–ú–ê–¢ –Ω“Ø“Ø—Ä –±“Ø—Ä—Ç–≥—ç—Ö (Space –¥–∞—Ä–∞—Ö —à–∞–∞—Ä–¥–ª–∞–≥–∞–≥“Ø–π)")
        print("  2 - –ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä–æ–æ—Å –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∞—Ö")
        print("  3 - –î–∞—Ç–∞–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö")
        print("  4 - –î–∞—Ç–∞–≥ –∞—á–∞–∞–ª–∞—Ö")
        print("  5 - –í–∏–¥–µ–æ–≥–æ–æ—Ä —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö")
        print("  6 - –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å–∏–π–≥ —Ö–∞—Ä–∞—Ö")
        print("  7 - –•“Ø–Ω–∏–π –¥–∞—Ç–∞–≥ —É—Å—Ç–≥–∞—Ö")
        print(
            "  8 - Threshold —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö (–æ–¥–æ–æ: {:.2f})".format(system.threshold))
        print("  0 - –ì–∞—Ä–∞—Ö")
        print("-" * 60)

        choice = input("–°–æ–Ω–≥–æ–ª—Ç: ").strip()

        if choice == '1':
            name = input("–•“Ø–Ω–∏–π –Ω—ç—Ä: ").strip()
            if name:
                num = input(
                    "–•—ç–¥—ç–Ω ”©–Ω—Ü–≥”©”©—Å –∞–≤–∞—Ö –≤—ç? (5-15, default=10): ").strip()
                num = int(num) if num.isdigit() else 10
                system.auto_collect_face_data(name, num, auto_save=True)
            else:
                print("‚ùå –ù—ç—Ä –æ—Ä—É—É–ª–Ω–∞ —É—É!")

        elif choice == '2':
            folder = input("–ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä—ã–Ω –∑–∞–º: ").strip()
            if folder:
                system.collect_face_data_from_images(folder)
            else:
                print("‚ùå –§–æ–ª–¥–µ—Ä—ã–Ω –∑–∞–º –æ—Ä—É—É–ª–Ω–∞ —É—É!")

        elif choice == '3':
            if system.known_face_features:
                system.save_data()
            else:
                print("‚ùå –•–∞–¥–≥–∞–ª–∞—Ö –¥–∞—Ç–∞ –±–∞–π—Ö–≥“Ø–π!")

        elif choice == '4':
            system.load_data()

        elif choice == '5':
            system.recognize_faces_video()

        elif choice == '6':
            system.list_people()

        elif choice == '7':
            system.list_people()
            name = input("\n–£—Å—Ç–≥–∞—Ö —Ö“Ø–Ω–∏–π –Ω—ç—Ä: ").strip()
            if name:
                if system.delete_person(name):
                    # –£—Å—Ç–≥–∞—Å–∞–Ω –±–æ–ª –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä —Ö–∞–¥–≥–∞–ª–∞—Ö
                    system.save_data()

        elif choice == '8':
            try:
                new_threshold = float(
                    input(f"–®–∏–Ω—ç threshold (0.7-0.95, –æ–¥–æ–æ={system.threshold:.2f}): "))
                if 0.7 <= new_threshold <= 0.95:
                    system.threshold = new_threshold
                    print(
                        f"‚úÖ Threshold {new_threshold:.2f} –±–æ–ª–≥–æ–∂ ”©”©—Ä—á–ª”©–≥–¥–ª”©”©")
                else:
                    print("‚ùå 0.7-0.95 —Ö–æ–æ—Ä–æ–Ω–¥ —É—Ç–≥–∞ –æ—Ä—É—É–ª–Ω–∞ —É—É!")
            except ValueError:
                print("‚ùå –ë—É—Ä—É—É —É—Ç–≥–∞!")

        elif choice == '0':
            print("\n" + "=" * 60)
            print("üëã –ë–∞—è—Ä—Ç–∞–π! –ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º —Ö–∞–∞–≥–¥–∞–∂ –±–∞–π–Ω–∞...")
            print("=" * 60)
            break

        else:
            print("‚ùå –ë—É—Ä—É—É —Å–æ–Ω–≥–æ–ª—Ç! –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüõë –ü—Ä–æ–≥—Ä–∞–º –∑–æ–≥—Å—Å–æ–Ω (Ctrl+C)")
    except Exception as e:
        print(f"\n‚ùå –ê–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}")
1