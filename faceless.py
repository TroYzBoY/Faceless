import cv2
import pickle
import os
import numpy as np
from datetime import datetime

class FaceRecognitionSystem:
    def __init__(self, threshold=0.85):
        self.known_face_features = []
        self.known_face_names = []
        self.data_file = "face_data.pkl"
        self.threshold = threshold  # –¢–∞–Ω–∏–ª—Ç—ã–Ω –±–æ—Å–≥–æ —É—Ç–≥–∞
        
        # OpenCV –Ω“Ø“Ø—Ä –æ–ª–æ—Ö classifier
        cascade_path = cv2.data.haarcascades
        self.face_cascade = cv2.CascadeClassifier(cascade_path + 'haarcascade_frontalface_default.xml')
        self.eye_cascade = cv2.CascadeClassifier(cascade_path + 'haarcascade_eye.xml')
        
        # Classifier –∞–º–∂–∏–ª—Ç—Ç–∞–π –∞—á–∞–∞–ª–∞–≥–¥—Å–∞–Ω —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞—Ö
        if self.face_cascade.empty() or self.eye_cascade.empty():
            raise Exception("‚ùå Haar Cascade —Ñ–∞–π–ª—É—É–¥ –∞—á–∞–∞–ª–∞–≥–¥—Å–∞–Ω–≥“Ø–π!")
        
    def extract_face_features(self, image, face_rect):
        """–ù“Ø“Ø—Ä–Ω–∏–π –æ–Ω—Ü–ª–æ–≥ —à–∏–Ω–∂ —á–∞–Ω–∞—Ä—É—É–¥—ã–≥ –≥–∞—Ä–≥–∞–∂ –∞–≤–∞—Ö"""
        try:
            x, y, w, h = face_rect
            
            # –•“Ø—Ä—ç—ç–Ω–∏–π —à–∞–ª–≥–∞–ª—Ç
            if x < 0 or y < 0 or x+w > image.shape[1] or y+h > image.shape[0]:
                return None
            
            face = image[y:y+h, x:x+w]
            
            if face.size == 0:
                return None
            
            # –ù“Ø“Ø—Ä–∏–π–≥ —Ç–æ–≥—Ç–º–æ–ª —Ö—ç–º–∂—ç—ç –±–æ–ª–≥–æ—Ö
            face_resized = cv2.resize(face, (100, 100))
            
            # Gray scale –±–æ–ª–≥–æ—Ö
            if len(face_resized.shape) == 3:
                gray_face = cv2.cvtColor(face_resized, cv2.COLOR_BGR2GRAY)
            else:
                gray_face = face_resized
            
            # –ì—ç—Ä—ç–ª—Ç“Ø“Ø–ª–≥–∏–π–Ω —Ç–æ–≥—Ç–≤–æ—Ä–∂—É—É–ª–∞–ª—Ç
            gray_face = cv2.equalizeHist(gray_face)
            
            # Histogram features
            hist = cv2.calcHist([gray_face], [0], None, [256], [0, 256])
            hist = cv2.normalize(hist, hist).flatten()
            
            # LBP features
            lbp_features = self.compute_lbp(gray_face)
            
            # HOG features (–∏–ª“Ø“Ø —Å–∞–π–Ω —Ç–∞–Ω–∏–ª—Ç)
            hog_features = self.compute_hog(gray_face)
            
            # –ë“Ø—Ö features-–∏–π–≥ –Ω—ç–≥—Ç–≥—ç—Ö
            features = np.concatenate([hist, lbp_features, hog_features])
            
            return features
        except Exception as e:
            print(f"‚ö†Ô∏è Features –≥–∞—Ä–≥–∞—Ö–∞–¥ –∞–ª–¥–∞–∞: {e}")
            return None
    
    def compute_lbp(self, image):
        """Local Binary Pattern features - —Å–∞–π–∂—Ä—É—É–ª—Å–∞–Ω —Ö—É–≤–∏–ª–±–∞—Ä"""
        height, width = image.shape
        radius = 1
        lbp = np.zeros((height-2*radius, width-2*radius), dtype=np.uint8)
        
        for i in range(radius, height-radius):
            for j in range(radius, width-radius):
                center = image[i, j]
                code = 0
                code |= (image[i-1, j-1] >= center) << 7
                code |= (image[i-1, j] >= center) << 6
                code |= (image[i-1, j+1] >= center) << 5
                code |= (image[i, j+1] >= center) << 4
                code |= (image[i+1, j+1] >= center) << 3
                code |= (image[i+1, j] >= center) << 2
                code |= (image[i+1, j-1] >= center) << 1
                code |= (image[i, j-1] >= center) << 0
                lbp[i-radius, j-radius] = code
        
        # LBP histogram - uniform patterns –∞—à–∏–≥–ª–∞—Ö
        hist_lbp = cv2.calcHist([lbp], [0], None, [256], [0, 256])
        hist_lbp = cv2.normalize(hist_lbp, hist_lbp).flatten()
        
        return hist_lbp
    
    def compute_hog(self, image):
        """HOG (Histogram of Oriented Gradients) features"""
        # Gradient —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö
        gx = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=1)
        gy = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=1)
        
        # Magnitude –±–æ–ª–æ–Ω angle
        mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)
        
        # Histogram (9 bins)
        bins = np.int32(angle / 40)  # 0-360 -> 0-8
        bin_cells = []
        
        # 10x10 cell —Ç—É—Å –±“Ø—Ä—ç—ç—Å histogram –∞–≤–∞—Ö
        cell_size = 10
        for i in range(0, image.shape[0] - cell_size, cell_size):
            for j in range(0, image.shape[1] - cell_size, cell_size):
                cell_mag = mag[i:i+cell_size, j:j+cell_size]
                cell_angle = bins[i:i+cell_size, j:j+cell_size]
                
                hist = np.zeros(9)
                for k in range(9):
                    hist[k] = np.sum(cell_mag[cell_angle == k])
                
                bin_cells.extend(hist)
        
        # Normalize
        hog_features = np.array(bin_cells)
        if np.linalg.norm(hog_features) > 0:
            hog_features = hog_features / np.linalg.norm(hog_features)
        
        return hog_features[:256]  # –•—ç–º–∂—ç—ç–≥ —Ö—è–∑–≥–∞–∞—Ä–ª–∞—Ö
    
    def collect_face_data_from_images(self, images_folder):
        """–ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä–æ–æ—Å –Ω“Ø“Ø—Ä–∏–π–≥ —Ç–∞–Ω–∏—É–ª–∞—Ö - —Å–∞–π–∂—Ä—É—É–ª—Å–∞–Ω"""
        print(f"üì∏ {images_folder}-–æ–æ—Å –Ω“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∂ –±–∞–π–Ω–∞...")
        
        if not os.path.exists(images_folder):
            print(f"‚ùå {images_folder} –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return
        
        image_files = [f for f in os.listdir(images_folder) 
                      if f.lower().endswith((".jpg", ".jpeg", ".png", ".bmp"))]
        
        if not image_files:
            print("‚ùå –ó—É—Ä–∞–≥ –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return
        
        success_count = 0
        for filename in image_files:
            image_path = os.path.join(images_folder, filename)
            image = cv2.imread(image_path)
            
            if image is None:
                print(f"‚ö†Ô∏è {filename} —É–Ω—à–∏–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π")
                continue
            
            # –ù“Ø“Ø—Ä –æ–ª–æ—Ö
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.1, minNeighbors=5, 
                minSize=(50, 50), maxSize=(500, 500)
            )
            
            if len(faces) > 0:
                # –•–∞–º–≥–∏–π–Ω —Ç–æ–º –Ω“Ø“Ø—Ä–∏–π–≥ –∞–≤–∞—Ö
                face = max(faces, key=lambda rect: rect[2] * rect[3])
                features = self.extract_face_features(image, face)
                
                if features is not None:
                    # –§–∞–π–ª—ã–Ω –Ω—ç—Ä–∏–π–≥ —Ö“Ø–Ω–∏–π –Ω—ç—Ä –±–æ–ª–≥–æ—Ö (extension-–≥ –∞–≤–∞—Ö)
                    name = os.path.splitext(filename)[0].replace('_', ' ').title()
                    self.known_face_features.append(features)
                    self.known_face_names.append(name)
                    success_count += 1
                    print(f"‚úÖ {name} —Ç–∞–Ω–∏—É–ª—Å–∞–Ω")
                else:
                    print(f"‚ö†Ô∏è {filename}-–Ω features –≥–∞—Ä–≥–∞–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π")
            else:
                print(f"‚ö†Ô∏è {filename}-–¥ –Ω“Ø“Ø—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π")
        
        print(f"\nüìä –ù–∏–π—Ç: {success_count}/{len(image_files)} –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏—É–ª—Å–∞–Ω")
    
    def collect_face_data_from_webcam(self, name, num_samples=10):
        """–í–µ–±–∫–∞–º–∞–∞—Å –Ω“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∞—Ö - —Å–∞–π–∂—Ä—É—É–ª—Å–∞–Ω"""
        print(f"üìπ {name}-—ã–Ω –Ω“Ø“Ø—Ä–∏–π–≥ {num_samples} —É–¥–∞–∞ –∞–≤–∞—Ö –≥—ç–∂ –±–∞–π–Ω–∞...")
        print("üí° ”®”©—Ä ”©”©—Ä ”©–Ω—Ü”©–≥, –≥—ç—Ä—ç–ª—Ç“Ø“Ø–ª—ç–≥—ç—ç—Ä –∑—É—Ä–∞–≥ –∞–≤–±–∞–ª —Å–∞–π–Ω!")
        
        video_capture = cv2.VideoCapture(0)
        
        if not video_capture.isOpened():
            print("‚ùå –ö–∞–º–µ—Ä –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
            return False
        
        features_list = []
        count = 0
        
        while count < num_samples:
            ret, frame = video_capture.read()
            if not ret:
                print("‚ùå –ö–∞–º–µ—Ä–∞–∞—Å frame —É–Ω—à–∏–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π!")
                break
            
            # –ù“Ø“Ø—Ä –æ–ª–æ—Ö
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50)
            )
            
            # –ù“Ø“Ø—Ä“Ø“Ø–¥–∏–π–≥ –∑—É—Ä–∞—Ö
            face_detected = False
            for (x, y, w, h) in faces:
                face_detected = True
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                
                # –ù“Ø–¥–∏–π–≥ –æ–ª–æ—Ö
                roi_gray = gray[y:y+h, x:x+w]
                eyes = self.eye_cascade.detectMultiScale(roi_gray, minNeighbors=8)
                for (ex, ey, ew, eh) in eyes:
                    cv2.circle(frame, (x+ex+ew//2, y+ey+eh//2), ew//2, (255, 0, 0), 2)
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –º—ç–¥—ç—ç–ª—ç–ª
            progress_text = f"–ê–≤—Å–∞–Ω: {count}/{num_samples}"
            cv2.putText(frame, progress_text, (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            instruction = "SPACE - –∑—É—Ä–∞–≥ –∞–≤–∞—Ö | Q - –≥–∞—Ä–∞—Ö"
            cv2.putText(frame, instruction, (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            if face_detected:
                status = "‚úì –ù“Ø“Ø—Ä –æ–ª–¥–ª–æ–æ! SPACE –¥–∞—Ä–Ω–∞ —É—É"
                color = (0, 255, 0)
            else:
                status = "‚úó –ù“Ø“Ø—Ä –æ–ª–æ—Ö—ã–≥ –æ—Ä–æ–ª–¥–æ–∂ –±–∞–π–Ω–∞..."
                color = (0, 0, 255)
            
            cv2.putText(frame, status, (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—É–ª–∞—Ö', frame)
            
            key = cv2.waitKey(1) & 0xFF
            
            # Space –¥–∞—Ä–∞—Ö–∞–¥ –∑—É—Ä–∞–≥ –∞–≤–∞—Ö
            if key == ord(' ') and len(faces) > 0:
                face = max(faces, key=lambda rect: rect[2] * rect[3])
                features = self.extract_face_features(frame, face)
                
                if features is not None:
                    features_list.append(features)
                    count += 1
                    print(f"‚úÖ –ó—É—Ä–∞–≥ {count}/{num_samples} –∞–≤–ª–∞–∞!")
                else:
                    print("‚ö†Ô∏è Features –≥–∞—Ä–≥–∞–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π, –¥–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É")
            
            # Q –¥–∞—Ä–∞—Ö–∞–¥ –≥–∞—Ä–∞—Ö
            elif key == ord('q'):
                print("üö´ –¶—É—Ü–ª–∞–≥–¥–ª–∞–∞")
                break
        
        video_capture.release()
        cv2.destroyAllWindows()
        
        # –î—É–Ω–¥–∞–∂ features –∞–≤–∞—Ö
        if len(features_list) >= 3:  # –•–∞–º–≥–∏–π–Ω –±–∞–≥–∞–¥–∞–∞ 3 –∑—É—Ä–∞–≥
            avg_features = np.mean(features_list, axis=0)
            self.known_face_features.append(avg_features)
            self.known_face_names.append(name)
            print(f"‚úÖ {name} –∞–º–∂–∏–ª—Ç—Ç–∞–π —Ç–∞–Ω–∏—É–ª—Å–∞–Ω! ({len(features_list)} –∑—É—Ä–∞–≥)")
            return True
        else:
            print(f"‚ùå –•–∞–Ω–≥–∞–ª—Ç—Ç–∞–π –∑—É—Ä–∞–≥ –∞–≤–∞–∞–≥“Ø–π! ({len(features_list)}/{num_samples})")
            return False
    
    def save_data(self):
        """–ù“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞–≥ —Ñ–∞–π–ª–¥ —Ö–∞–¥–≥–∞–ª–∞—Ö"""
        try:
            data = {
                'features': self.known_face_features,
                'names': self.known_face_names,
                'threshold': self.threshold,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            with open(self.data_file, 'wb') as f:
                pickle.dump(data, f)
            print(f"üíæ {len(self.known_face_names)} —Ö“Ø–Ω–∏–π –¥–∞—Ç–∞ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞!")
            print(f"üìÅ –§–∞–π–ª: {self.data_file}")
        except Exception as e:
            print(f"‚ùå –•–∞–¥–≥–∞–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}")
    
    def load_data(self):
        """–•–∞–¥–≥–∞–ª—Å–∞–Ω –¥–∞—Ç–∞–≥ –∞—á–∞–∞–ª–∞—Ö"""
        if not os.path.exists(self.data_file):
            print(f"‚ùå {self.data_file} —Ñ–∞–π–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False
        
        try:
            with open(self.data_file, 'rb') as f:
                data = pickle.load(f)
                self.known_face_features = data['features']
                self.known_face_names = data['names']
                
                if 'threshold' in data:
                    self.threshold = data['threshold']
                
                if 'timestamp' in data:
                    print(f"üìÖ –•–∞–¥–≥–∞–ª—Å–∞–Ω –æ–≥–Ω–æ–æ: {data['timestamp']}")
            
            print(f"‚úÖ {len(self.known_face_names)} —Ö“Ø–Ω–∏–π –¥–∞—Ç–∞ –∞—á–∞–∞–ª–∞–≥–¥–ª–∞–∞!")
            print(f"üë§ –•“Ø–º“Ø“Ø—Å: {', '.join(set(self.known_face_names))}")
            return True
        except Exception as e:
            print(f"‚ùå –ê—á–∞–∞–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}")
            return False
    
    def compare_faces(self, features1, features2):
        """–•–æ—ë—Ä –Ω“Ø“Ø—Ä–∏–π–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö - –æ–ª–æ–Ω –∞—Ä–≥–∞–∞—Ä"""
        # 1. Cosine similarity
        cos_sim = np.dot(features1, features2) / (
            np.linalg.norm(features1) * np.linalg.norm(features2) + 1e-6
        )
        
        # 2. Euclidean distance (normalized)
        euclidean_dist = np.linalg.norm(features1 - features2)
        euclidean_sim = 1 / (1 + euclidean_dist)
        
        # –•–æ—ë—Ä—ã–≥ —Ö–æ—Å–ª—É—É–ª–∞—Ö (weighted average)
        similarity = 0.7 * cos_sim + 0.3 * euclidean_sim
        
        is_match = similarity > self.threshold
        
        return similarity, is_match
    
    def recognize_faces_video(self):
        """–í–∏–¥–µ–æ–≥–æ–æ—Ä –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö - —Å–∞–π–∂—Ä—É—É–ª—Å–∞–Ω"""
        if not self.known_face_features:
            print("‚ùå –≠—Ö–ª—ç—ç–¥ –¥–∞—Ç–∞ –∞—á–∞–∞–ª–Ω–∞ —É—É —ç—Å–≤—ç–ª –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏—É–ª–Ω–∞ —É—É!")
            return
        
        print(f"üé• –ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º —ç—Ö—ç–ª–ª—ç—ç ({len(self.known_face_names)} —Ö“Ø–Ω)")
        print("Q –¥–∞—Ä–∂ –≥–∞—Ä–Ω–∞ —É—É!")
        
        video_capture = cv2.VideoCapture(0)
        
        if not video_capture.isOpened():
            print("‚ùå –ö–∞–º–µ—Ä –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
            return
        
        frame_count = 0
        fps_start_time = datetime.now()
        fps = 0
        
        while True:
            ret, frame = video_capture.read()
            if not ret:
                break
            
            frame_count += 1
            
            # FPS —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö
            if frame_count % 30 == 0:
                fps_end_time = datetime.now()
                time_diff = (fps_end_time - fps_start_time).total_seconds()
                fps = 30 / time_diff if time_diff > 0 else 0
                fps_start_time = fps_end_time
            
            # –•—É—Ä–¥—ã–≥ —Å–∞–π–∂—Ä—É—É–ª–∞—Ö—ã–Ω —Ç—É–ª–¥ 2 frame —Ç—É—Ç–∞–º–¥ —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö
            if frame_count % 2 != 0:
                cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
                continue
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.1, minNeighbors=5, 
                minSize=(50, 50), maxSize=(500, 500)
            )
            
            for (x, y, w, h) in faces:
                # –ù“Ø“Ø—Ä–Ω–∏–π features –≥–∞—Ä–≥–∞—Ö
                features = self.extract_face_features(frame, (x, y, w, h))
                
                if features is None:
                    continue
                
                name = "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π"
                confidence = 0
                
                # –ë“Ø—Ö —Ç–∞–Ω–∏—É–ª—Å–∞–Ω –Ω“Ø“Ø—Ä—Ç—ç–π —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö
                max_similarity = 0
                best_match_idx = -1
                
                for idx, known_features in enumerate(self.known_face_features):
                    similarity, is_match = self.compare_faces(known_features, features)
                    if similarity > max_similarity:
                        max_similarity = similarity
                        best_match_idx = idx
                
                # Threshold —à–∞–ª–≥–∞—Ö
                if max_similarity > self.threshold:
                    name = self.known_face_names[best_match_idx]
                    confidence = max_similarity * 100
                
                # –•“Ø—Ä—ç—ç –∑—É—Ä–∞—Ö - ”©–Ω–≥”© –Ω—å –∏—Ç–≥—ç–ª–∏–π–Ω —Ç“Ø–≤—à–∏–Ω—ç—ç—Å —Ö–∞–º–∞–∞—Ä–Ω–∞
                if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π":
                    if confidence > 90:
                        color = (0, 255, 0)  # –ù–æ–≥–æ–æ–Ω - –º–∞—à —Å–∞–π–Ω
                    elif confidence > 85:
                        color = (0, 255, 255)  # –®–∞—Ä - –¥—É–Ω–¥ –∑—ç—Ä—ç–≥
                    else:
                        color = (0, 165, 255)  # –£–ª–±–∞—Ä —à–∞—Ä
                else:
                    color = (0, 0, 255)  # –£–ª–∞–∞–Ω - —Ç–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π
                
                # –•“Ø—Ä—ç—ç
                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                
                # –ù—ç—Ä–Ω–∏–π –¥—ç–≤—Å–≥—ç—Ä
                label_y = y - 10 if y - 10 > 10 else y + h + 20
                cv2.rectangle(frame, (x, label_y - 25), (x+w, label_y), color, cv2.FILLED)
                
                # –ù—ç—Ä –±–∏—á–∏—Ö
                text = f"{name} ({confidence:.0f}%)" if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π" else name
                cv2.putText(frame, text, (x + 5, label_y - 5),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # FPS –º—ç–¥—ç—ç–ª—ç–ª
            cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # –¢–∞–Ω–∏–≥–¥—Å–∞–Ω –Ω“Ø“Ø—Ä–∏–π–Ω —Ç–æ–æ
            cv2.putText(frame, f"–ù“Ø“Ø—Ä: {len(faces)}", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º', frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        video_capture.release()
        cv2.destroyAllWindows()
        print("üëã –°–∏—Å—Ç–µ–º —Ö–∞–∞–≥–¥–ª–∞–∞")
    
    def delete_person(self, name):
        """–•“Ø–Ω–∏–π –¥–∞—Ç–∞–≥ —É—Å—Ç–≥–∞—Ö"""
        indices_to_remove = [i for i, n in enumerate(self.known_face_names) if n == name]
        
        if not indices_to_remove:
            print(f"‚ùå {name} –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False
        
        # –£—Ä–≤—É—É –¥–∞—Ä–∞–∞–ª–ª–∞–∞—Ä —É—Å—Ç–≥–∞—Ö (index ”©”©—Ä—á–ª”©–≥–¥”©—Ö–≥“Ø–π–Ω —Ç—É–ª–¥)
        for idx in sorted(indices_to_remove, reverse=True):
            del self.known_face_features[idx]
            del self.known_face_names[idx]
        
        print(f"‚úÖ {name} ({len(indices_to_remove)} –∑—É—Ä–∞–≥) —É—Å—Ç–≥–∞–≥–¥–ª–∞–∞!")
        return True
    
    def list_people(self):
        """–ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö"""
        if not self.known_face_names:
            print("üìã –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–Ω –±–∞–π—Ö–≥“Ø–π")
            return
        
        from collections import Counter
        name_counts = Counter(self.known_face_names)
        
        print(f"\nüìã –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å ({len(name_counts)}):")
        print("=" * 50)
        for name, count in sorted(name_counts.items()):
            print(f"  üë§ {name}: {count} –∑—É—Ä–∞–≥")
        print("=" * 50)

# ================ –•–≠–†–≠–ì–õ–≠–• –ñ–ò–®–≠–≠ ================

def main():
    system = FaceRecognitionSystem(threshold=0.85)
    
    print("=" * 60)
    print("üéØ –ù“Æ“Æ–† –¢–ê–ù–ò–• –°–ò–°–¢–ï–ú (OpenCV + Haar Cascade + HOG + LBP)")
    print("=" * 60)
    
    while True:
        print("\nüìã “Æ–ô–õ –ê–ñ–ò–õ–õ–ê–ì–ê–ê:")
        print("  1 - –í–µ–±–∫–∞–º–∞–∞—Å –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∞—Ö")
        print("  2 - –ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä–æ–æ—Å –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∞—Ö")
        print("  3 - –î–∞—Ç–∞–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö")
        print("  4 - –î–∞—Ç–∞–≥ –∞—á–∞–∞–ª–∞—Ö")
        print("  5 - –í–∏–¥–µ–æ–≥–æ–æ—Ä —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö")
        print("  6 - –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å–∏–π–≥ —Ö–∞—Ä–∞—Ö")
        print("  7 - –•“Ø–Ω–∏–π –¥–∞—Ç–∞–≥ —É—Å—Ç–≥–∞—Ö")
        print("  8 - Threshold —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö (–æ–¥–æ–æ: {:.2f})".format(system.threshold))
        print("  0 - –ì–∞—Ä–∞—Ö")
        print("-" * 60)
        
        choice = input("–°–æ–Ω–≥–æ–ª—Ç: ").strip()
        
        if choice == '1':
            name = input("–•“Ø–Ω–∏–π –Ω—ç—Ä: ").strip()
            if name:
                num = input("–•—ç–¥—ç–Ω –∑—É—Ä–∞–≥ –∞–≤–∞—Ö –≤—ç? (5-15, default=10): ").strip()
                num = int(num) if num.isdigit() else 10
                system.collect_face_data_from_webcam(name, num)
            else:
                print("‚ùå –ù—ç—Ä –æ—Ä—É—É–ª–Ω–∞ —É—É!")
                
        elif choice == '2':
            folder = input("–ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä—ã–Ω –∑–∞–º: ").strip()
            if folder:
                system.collect_face_data_from_images(folder)
            else:
                print("‚ùå –§–æ–ª–¥–µ—Ä—ã–Ω –∑–∞–º –æ—Ä—É—É–ª–Ω–∞ —É—É!")
                
        elif choice == '3':
            if system.known_face_features:
                system.save_data()
            else:
                print("‚ùå –•–∞–¥–≥–∞–ª–∞—Ö –¥–∞—Ç–∞ –±–∞–π—Ö–≥“Ø–π!")
            
        elif choice == '4':
            system.load_data()
            
        elif choice == '5':
            system.recognize_faces_video()
            
        elif choice == '6':
            system.list_people()
            
        elif choice == '7':
            system.list_people()
            name = input("\n–£—Å—Ç–≥–∞—Ö —Ö“Ø–Ω–∏–π –Ω—ç—Ä: ").strip()
            if name:
                system.delete_person(name)
            
        elif choice == '8':
            try:
                new_threshold = float(input(f"–®–∏–Ω—ç threshold (0.7-0.95, –æ–¥–æ–æ={system.threshold:.2f}): "))
                if 0.7 <= new_threshold <= 0.95:
                    system.threshold = new_threshold
                    print(f"‚úÖ Threshold {new_threshold:.2f} –±–æ–ª–≥–æ–∂ ”©”©—Ä—á–ª”©–≥–¥–ª”©”©")
                else:
                    print("‚ùå 0.7-0.95 —Ö–æ–æ—Ä–æ–Ω–¥ —É—Ç–≥–∞ –æ—Ä—É—É–ª–Ω–∞ —É—É!")
            except ValueError:
                print("‚ùå –ë—É—Ä—É—É —É—Ç–≥–∞!")
                
        elif choice == '0':
            print("\n" + "=" * 60)
            print("üëã –ë–∞—è—Ä—Ç–∞–π! –ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º —Ö–∞–∞–≥–¥–∞–∂ –±–∞–π–Ω–∞...")
            print("=" * 60)
            break
            
        else:
            print("‚ùå –ë—É—Ä—É—É —Å–æ–Ω–≥–æ–ª—Ç! –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüõë –ü—Ä–æ–≥—Ä–∞–º –∑–æ–≥—Å—Å–æ–Ω (Ctrl+C)")
    except Exception as e:
        print(f"\n‚ùå –ê–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}")
        1