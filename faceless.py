import tkinter as tk
from tkinter import ttk, messagebox, filedialog
import cv2
from PIL import Image, ImageTk
import pickle
import time
from datetime import datetime
import numpy as np
import os
from collections import Counter
import threading


class FaceRecognitionGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("üéØ –ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º")
        self.root.geometry("1200x800")
        self.root.configure(bg='#1e1e2e')
        
        # Initialize face recognition system
        self.known_face_features = []
        self.known_face_names = []
        self.data_file = "face_data.pkl"
        self.threshold = 0.72
        
        # OpenCV cascades
        cascade_path = cv2.data.haarcascades
        self.face_cascade = cv2.CascadeClassifier(
            cascade_path + 'haarcascade_frontalface_default.xml')
        self.eye_cascade = cv2.CascadeClassifier(
            cascade_path + 'haarcascade_eye.xml')
        
        # Video capture variables
        self.video_capture = None
        self.is_capturing = False
        self.current_mode = None  # 'register' or 'recognize'
        
        self.setup_ui()
        self.load_data_silent()
    
    def setup_ui(self):
        """Setup the user interface"""
        # Title bar
        title_frame = tk.Frame(self.root, bg='#2d2d44', height=80)
        title_frame.pack(fill='x', pady=(0, 10))
        
        title_label = tk.Label(
            title_frame, 
            text="üì± AUTO FACE ID –°–ò–°–¢–ï–ú", 
            font=('Helvetica', 24, 'bold'),
            bg='#2d2d44',
            fg='#00ff88'
        )
        title_label.pack(pady=20)
        
        # Main container
        main_container = tk.Frame(self.root, bg='#1e1e2e')
        main_container.pack(fill='both', expand=True, padx=20, pady=10)
        
        # Left panel - Controls
        left_panel = tk.Frame(main_container, bg='#2d2d44', width=350)
        left_panel.pack(side='left', fill='both', padx=(0, 10))
        
        # Control buttons
        control_frame = tk.LabelFrame(
            left_panel, 
            text="‚öôÔ∏è “Æ–Ω–¥—Å—ç–Ω “Ø–π–ª–¥–ª“Ø“Ø–¥", 
            font=('Helvetica', 12, 'bold'),
            bg='#2d2d44',
            fg='#ffffff',
            padx=15,
            pady=15
        )
        control_frame.pack(fill='x', pady=10, padx=10)
        
        # Register button
        self.register_btn = self.create_button(
            control_frame, 
            "ü§ñ –ù“Ø“Ø—Ä –±“Ø—Ä—Ç–≥—ç—Ö", 
            self.start_registration,
            '#00ff88'
        )
        self.register_btn.pack(fill='x', pady=5)
        
        # Recognize button
        self.recognize_btn = self.create_button(
            control_frame, 
            "üé• –¢–∞–Ω–∏–ª—Ç —ç—Ö–ª“Ø“Ø–ª—ç—Ö", 
            self.start_recognition,
            '#00aaff'
        )
        self.recognize_btn.pack(fill='x', pady=5)
        
        # Stop button
        self.stop_btn = self.create_button(
            control_frame, 
            "‚èπÔ∏è –ó–æ–≥—Å–æ–æ—Ö", 
            self.stop_capture,
            '#ff4444'
        )
        self.stop_btn.pack(fill='x', pady=5)
        self.stop_btn.config(state='disabled')
        
        # Data management
        data_frame = tk.LabelFrame(
            left_panel, 
            text="üíæ –î–∞—Ç–∞ —É–¥–∏—Ä–¥–ª–∞–≥–∞", 
            font=('Helvetica', 12, 'bold'),
            bg='#2d2d44',
            fg='#ffffff',
            padx=15,
            pady=15
        )
        data_frame.pack(fill='x', pady=10, padx=10)
        
        self.create_button(
            data_frame, 
            "üìÇ –î–∞—Ç–∞ –∞—á–∞–∞–ª–∞—Ö", 
            self.load_data,
            '#9966ff'
        ).pack(fill='x', pady=5)
        
        self.create_button(
            data_frame, 
            "üíæ –î–∞—Ç–∞ —Ö–∞–¥–≥–∞–ª–∞—Ö", 
            self.save_data,
            '#9966ff'
        ).pack(fill='x', pady=5)
        
        self.create_button(
            data_frame, 
            "üë• –•“Ø–º“Ø“Ø—Å–∏–π–≥ —Ö–∞—Ä–∞—Ö", 
            self.show_people_list,
            '#ff9500'
        ).pack(fill='x', pady=5)
        
        self.create_button(
            data_frame, 
            "üóëÔ∏è –•“Ø–Ω —É—Å—Ç–≥–∞—Ö", 
            self.delete_person,
            '#ff4444'
        ).pack(fill='x', pady=5)
        
        # Settings
        settings_frame = tk.LabelFrame(
            left_panel, 
            text="‚öôÔ∏è –¢–æ—Ö–∏—Ä–≥–æ–æ", 
            font=('Helvetica', 12, 'bold'),
            bg='#2d2d44',
            fg='#ffffff',
            padx=15,
            pady=15
        )
        settings_frame.pack(fill='x', pady=10, padx=10)
        
        # Threshold slider
        tk.Label(
            settings_frame, 
            text="Threshold:", 
            bg='#2d2d44', 
            fg='#ffffff',
            font=('Helvetica', 10)
        ).pack(anchor='w')
        
        self.threshold_var = tk.DoubleVar(value=self.threshold)
        threshold_slider = ttk.Scale(
            settings_frame,
            from_=0.70,
            to=0.95,
            variable=self.threshold_var,
            orient='horizontal',
            command=self.update_threshold
        )
        threshold_slider.pack(fill='x', pady=5)
        
        self.threshold_label = tk.Label(
            settings_frame,
            text=f"–£—Ç–≥–∞: {self.threshold:.2f}",
            bg='#2d2d44',
            fg='#00ff88',
            font=('Helvetica', 9)
        )
        self.threshold_label.pack()
        
        # Status info
        status_frame = tk.LabelFrame(
            left_panel, 
            text="üìä –ú—ç–¥—ç—ç–ª—ç–ª", 
            font=('Helvetica', 12, 'bold'),
            bg='#2d2d44',
            fg='#ffffff',
            padx=15,
            pady=15
        )
        status_frame.pack(fill='both', expand=True, pady=10, padx=10)
        
        self.status_text = tk.Text(
            status_frame,
            height=10,
            bg='#1e1e2e',
            fg='#ffffff',
            font=('Courier', 9),
            wrap='word',
            state='disabled'
        )
        self.status_text.pack(fill='both', expand=True)
        
        # Right panel - Video feed
        right_panel = tk.Frame(main_container, bg='#2d2d44')
        right_panel.pack(side='right', fill='both', expand=True)
        
        video_label_frame = tk.LabelFrame(
            right_panel,
            text="üìπ –í–∏–¥–µ–æ",
            font=('Helvetica', 12, 'bold'),
            bg='#2d2d44',
            fg='#ffffff'
        )
        video_label_frame.pack(fill='both', expand=True, padx=10, pady=10)
        
        self.video_label = tk.Label(
            video_label_frame,
            bg='#1e1e2e',
            text="–í–∏–¥–µ–æ –∑–æ–≥—Å—Å–æ–Ω –±–∞–π–Ω–∞\n\nüé• '–ù“Ø“Ø—Ä –±“Ø—Ä—Ç–≥—ç—Ö' —ç—Å–≤—ç–ª '–¢–∞–Ω–∏–ª—Ç —ç—Ö–ª“Ø“Ø–ª—ç—Ö' –¥–∞—Ä–Ω–∞ —É—É",
            font=('Helvetica', 14),
            fg='#666666'
        )
        self.video_label.pack(fill='both', expand=True, padx=10, pady=10)
        
        self.update_status_display()
    
    def create_button(self, parent, text, command, color):
        """Create a styled button"""
        btn = tk.Button(
            parent,
            text=text,
            command=command,
            bg=color,
            fg='#ffffff',
            font=('Helvetica', 11, 'bold'),
            relief='flat',
            cursor='hand2',
            height=2,
            activebackground=self.lighten_color(color)
        )
        return btn
    
    def lighten_color(self, color):
        """Lighten a hex color"""
        # Simple color lightening
        if color == '#00ff88':
            return '#33ff99'
        elif color == '#00aaff':
            return '#33bbff'
        elif color == '#ff4444':
            return '#ff6666'
        elif color == '#9966ff':
            return '#aa77ff'
        elif color == '#ff9500':
            return '#ffaa33'
        return color
    
    def update_status(self, message, clear=False):
        """Update status text"""
        self.status_text.config(state='normal')
        if clear:
            self.status_text.delete(1.0, tk.END)
        self.status_text.insert(tk.END, f"{message}\n")
        self.status_text.see(tk.END)
        self.status_text.config(state='disabled')
    
    def update_status_display(self):
        """Update the status information"""
        self.update_status("", clear=True)
        if self.known_face_names:
            name_counts = Counter(self.known_face_names)
            self.update_status(f"üë• –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π: {len(name_counts)} —Ö“Ø–Ω")
            self.update_status(f"üìä –ù–∏–π—Ç –∑—É—Ä–∞–≥: {len(self.known_face_names)}")
            self.update_status(f"üéØ Threshold: {self.threshold:.2f}\n")
            self.update_status("–•“Ø–º“Ø“Ø—Å:")
            for name, count in sorted(name_counts.items()):
                self.update_status(f"  ‚Ä¢ {name}: {count} –∑—É—Ä–∞–≥")
        else:
            self.update_status("‚ö†Ô∏è –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–Ω –±–∞–π—Ö–≥“Ø–π")
    
    def update_threshold(self, value):
        """Update threshold value"""
        self.threshold = float(value)
        self.threshold_label.config(text=f"–£—Ç–≥–∞: {self.threshold:.2f}")
    
    def start_registration(self):
        """Start face registration process"""
        if self.is_capturing:
            messagebox.showwarning("–ê–Ω—Ö–∞–∞—Ä—É—É–ª–≥–∞", "”®”©—Ä “Ø–π–ª–¥—ç–ª —è–≤–∞–≥–¥–∞–∂ –±–∞–π–Ω–∞!")
            return
        
        # Get name dialog
        dialog = tk.Toplevel(self.root)
        dialog.title("–ù—ç—Ä –æ—Ä—É—É–ª–∞—Ö")
        dialog.geometry("400x200")
        dialog.configure(bg='#2d2d44')
        dialog.transient(self.root)
        dialog.grab_set()
        
        tk.Label(
            dialog,
            text="–•“Ø–Ω–∏–π –Ω—ç—Ä –æ—Ä—É—É–ª–Ω–∞ —É—É:",
            font=('Helvetica', 12),
            bg='#2d2d44',
            fg='#ffffff'
        ).pack(pady=20)
        
        name_entry = tk.Entry(
            dialog,
            font=('Helvetica', 12),
            width=30
        )
        name_entry.pack(pady=10)
        name_entry.focus()
        
        def submit():
            name = name_entry.get().strip()
            if name:
                dialog.destroy()
                self.current_mode = 'register'
                self.register_name = name
                self.register_samples = 10
                threading.Thread(target=self.register_face_thread, daemon=True).start()
            else:
                messagebox.showerror("–ê–ª–¥–∞–∞", "–ù—ç—Ä –æ—Ä—É—É–ª–Ω–∞ —É—É!")
        
        tk.Button(
            dialog,
            text="‚úì –≠—Ö–ª“Ø“Ø–ª—ç—Ö",
            command=submit,
            bg='#00ff88',
            fg='#ffffff',
            font=('Helvetica', 11, 'bold'),
            cursor='hand2',
            height=2
        ).pack(pady=10)
        
        name_entry.bind('<Return>', lambda e: submit())
    
    def register_face_thread(self):
        """Register face in separate thread"""
        self.is_capturing = True
        self.register_btn.config(state='disabled')
        self.recognize_btn.config(state='disabled')
        self.stop_btn.config(state='normal')
        
        self.update_status(f"\nüì± {self.register_name} –±“Ø—Ä—Ç–≥—ç–∂ –±–∞–π–Ω–∞...")
        
        self.video_capture = cv2.VideoCapture(0)
        
        features_list = []
        count = 0
        face_positions = []
        last_capture_time = time.time()
        stable_frames = 0
        
        while count < self.register_samples and self.is_capturing:
            ret, frame = self.video_capture.read()
            if not ret:
                break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.1, minNeighbors=5,
                minSize=(100, 100), maxSize=(400, 400)
            )
            
            current_time = time.time()
            
            for (x, y, w, h) in faces:
                roi_gray = gray[y:y+h, x:x+w]
                eyes = self.eye_cascade.detectMultiScale(roi_gray, minNeighbors=8)
                has_eyes = len(eyes) >= 2
                
                face_center = (x + w//2, y + h//2)
                is_new_angle = self.is_new_angle(face_center, face_positions)
                
                if has_eyes and is_new_angle:
                    color = (0, 255, 0)
                    stable_frames += 1
                    ready = stable_frames >= 3
                else:
                    color = (0, 255, 255) if has_eyes else (0, 165, 255)
                    stable_frames = 0
                    ready = False
                
                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                
                if ready and current_time - last_capture_time >= 0.5:
                    features = self.extract_face_features(frame, (x, y, w, h))
                    if features is not None:
                        features_list.append(features)
                        face_positions.append(face_center)
                        count += 1
                        last_capture_time = current_time
                        stable_frames = 0
                        self.update_status(f"üì∏ {count}/{self.register_samples} –∞–≤–ª–∞–∞!")
            
            # Draw progress
            self.draw_progress(frame, count, self.register_samples)
            
            # Display frame
            self.display_frame(frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        self.video_capture.release()
        
        if len(features_list) >= 3:
            for features in features_list:
                self.known_face_features.append(features)
                self.known_face_names.append(self.register_name)
            
            self.update_status(f"‚úÖ {self.register_name} –∞–º–∂–∏–ª—Ç—Ç–∞–π –±“Ø—Ä—Ç–≥—ç–≥–¥–ª—ç—ç!")
            self.save_data()
            self.update_status_display()
        else:
            self.update_status(f"‚ùå –•–∞–Ω–≥–∞–ª—Ç—Ç–∞–π –∑—É—Ä–∞–≥ –∞–≤–∞–∞–≥“Ø–π!")
        
        self.stop_capture()
    
    def start_recognition(self):
        """Start face recognition"""
        if not self.known_face_features:
            messagebox.showwarning("–ê–Ω—Ö–∞–∞—Ä—É—É–ª–≥–∞", "–≠—Ö–ª—ç—ç–¥ –¥–∞—Ç–∞ –∞—á–∞–∞–ª–Ω–∞ —É—É!")
            return
        
        if self.is_capturing:
            messagebox.showwarning("–ê–Ω—Ö–∞–∞—Ä—É—É–ª–≥–∞", "”®”©—Ä “Ø–π–ª–¥—ç–ª —è–≤–∞–≥–¥–∞–∂ –±–∞–π–Ω–∞!")
            return
        
        self.current_mode = 'recognize'
        self.is_capturing = True
        self.register_btn.config(state='disabled')
        self.recognize_btn.config(state='disabled')
        self.stop_btn.config(state='normal')
        
        self.update_status("\nüé• –¢–∞–Ω–∏–ª—Ç —ç—Ö—ç–ª–ª—ç—ç...")
        
        threading.Thread(target=self.recognize_thread, daemon=True).start()
    
    def recognize_thread(self):
        """Recognition thread"""
        self.video_capture = cv2.VideoCapture(0)
        
        frame_count = 0
        last_results = {}
        
        while self.is_capturing:
            ret, frame = self.video_capture.read()
            if not ret:
                break
            
            frame_count += 1
            
            if frame_count % 3 == 0:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                faces = self.face_cascade.detectMultiScale(
                    gray, scaleFactor=1.2, minNeighbors=5,
                    minSize=(60, 60), maxSize=(400, 400)
                )
                
                new_results = {}
                
                for face_id, (x, y, w, h) in enumerate(faces):
                    features = self.extract_face_features(frame, (x, y, w, h))
                    
                    if features is not None:
                        name, confidence = self.find_best_match(features)
                        new_results[face_id] = (x, y, w, h, name, confidence)
                
                last_results = new_results
            
            # Draw results
            for face_id, (x, y, w, h, name, confidence) in last_results.items():
                color = self.get_color(name, confidence)
                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                
                label_y = y - 10 if y - 10 > 10 else y + h + 20
                cv2.rectangle(frame, (x, label_y - 25), (x+w, label_y), color, -1)
                
                text = f"{name} ({confidence:.0f}%)" if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π" else name
                cv2.putText(frame, text, (x + 5, label_y - 5),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            self.display_frame(frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        self.video_capture.release()
        self.stop_capture()
    
    def stop_capture(self):
        """Stop video capture"""
        self.is_capturing = False
        if self.video_capture:
            self.video_capture.release()
        
        self.register_btn.config(state='normal')
        self.recognize_btn.config(state='normal')
        self.stop_btn.config(state='disabled')
        
        # Clear video label
        self.video_label.config(
            image='',
            text="–í–∏–¥–µ–æ –∑–æ–≥—Å—Å–æ–Ω –±–∞–π–Ω–∞\n\nüé• '–ù“Ø“Ø—Ä –±“Ø—Ä—Ç–≥—ç—Ö' —ç—Å–≤—ç–ª '–¢–∞–Ω–∏–ª—Ç —ç—Ö–ª“Ø“Ø–ª—ç—Ö' –¥–∞—Ä–Ω–∞ —É—É"
        )
    
    def display_frame(self, frame):
        """Display frame in GUI"""
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = Image.fromarray(frame_rgb)
        
        # Resize to fit
        max_width = 800
        max_height = 600
        img.thumbnail((max_width, max_height), Image.Resampling.LANCZOS)
        
        imgtk = ImageTk.PhotoImage(image=img)
        self.video_label.imgtk = imgtk
        self.video_label.config(image=imgtk, text='')
    
    def draw_progress(self, frame, current, total):
        """Draw progress bar"""
        bar_width = frame.shape[1] - 40
        bar_height = 30
        bar_x, bar_y = 20, frame.shape[0] - 50
        
        cv2.rectangle(frame, (bar_x-5, bar_y-5),
                     (bar_x + bar_width + 5, bar_y + bar_height + 5),
                     (50, 50, 50), -1)
        
        progress = int((current / total) * bar_width)
        cv2.rectangle(frame, (bar_x, bar_y),
                     (bar_x + progress, bar_y + bar_height),
                     (0, 255, 0), -1)
        
        text = f"{current}/{total}"
        cv2.putText(frame, text, (bar_x + bar_width//2 - 30, bar_y + 20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    def is_new_angle(self, face_center, face_positions, min_diff=20):
        """Check if face position is new"""
        for prev_pos in face_positions:
            distance = np.sqrt((face_center[0] - prev_pos[0])**2 +
                             (face_center[1] - prev_pos[1])**2)
            if distance < min_diff:
                return False
        return True
    
    def extract_face_features(self, image, face_rect):
        """Extract face features"""
        try:
            x, y, w, h = face_rect
            face = image[y:y+h, x:x+w]
            face_resized = cv2.resize(face, (100, 100))
            
            if len(face_resized.shape) == 3:
                gray_face = cv2.cvtColor(face_resized, cv2.COLOR_BGR2GRAY)
            else:
                gray_face = face_resized
            
            gray_face = cv2.equalizeHist(gray_face)
            hist = cv2.calcHist([gray_face], [0], None, [256], [0, 256])
            hist = cv2.normalize(hist, hist).flatten()
            
            return hist
        except:
            return None
    
    def find_best_match(self, features):
        """Find best matching face"""
        max_similarity = 0
        best_match_name = "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π"
        
        for idx, known_features in enumerate(self.known_face_features):
            similarity = np.dot(features, known_features) / (
                np.linalg.norm(features) * np.linalg.norm(known_features) + 1e-6
            )
            
            if similarity > max_similarity:
                max_similarity = similarity
                best_match_name = self.known_face_names[idx]
        
        if max_similarity > self.threshold:
            return best_match_name, max_similarity * 100
        else:
            return "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π", 0
    
    def get_color(self, name, confidence):
        """Get color based on confidence"""
        if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π":
            if confidence > 90:
                return (0, 255, 0)
            elif confidence > 85:
                return (0, 255, 255)
            else:
                return (0, 165, 255)
        return (0, 0, 255)
    
    def save_data(self):
        """Save face data"""
        if not self.known_face_features:
            messagebox.showwarning("–ê–Ω—Ö–∞–∞—Ä—É—É–ª–≥–∞", "–•–∞–¥–≥–∞–ª–∞—Ö –¥–∞—Ç–∞ –±–∞–π—Ö–≥“Ø–π!")
            return
        
        try:
            data = {
                'features': self.known_face_features,
                'names': self.known_face_names,
                'threshold': self.threshold,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            with open(self.data_file, 'wb') as f:
                pickle.dump(data, f)
            
            self.update_status("üíæ –î–∞—Ç–∞ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞!")
            messagebox.showinfo("–ê–º–∂–∏–ª—Ç", "–î–∞—Ç–∞ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞!")
        except Exception as e:
            messagebox.showerror("–ê–ª–¥–∞–∞", f"–•–∞–¥–≥–∞–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞: {e}")
    
    def load_data_silent(self):
        """Load data silently on startup"""
        if os.path.exists(self.data_file):
            try:
                with open(self.data_file, 'rb') as f:
                    data = pickle.load(f)
                    self.known_face_features = data['features']
                    self.known_face_names = data['names']
                    if 'threshold' in data:
                        self.threshold = data['threshold']
                        self.threshold_var.set(self.threshold)
            except:
                pass
    
    def load_data(self):
        """Load face data"""
        if not os.path.exists(self.data_file):
            messagebox.showwarning("–ê–Ω—Ö–∞–∞—Ä—É—É–ª–≥–∞", "–î–∞—Ç–∞ —Ñ–∞–π–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return
        
        try:
            with open(self.data_file, 'rb') as f:
                data = pickle.load(f)
                self.known_face_features = data['features']
                self.known_face_names = data['names']
                if 'threshold' in data:
                    self.threshold = data['threshold']
                    self.threshold_var.set(self.threshold)
            
            self.update_status_display()
            messagebox.showinfo("–ê–º–∂–∏–ª—Ç", "–î–∞—Ç–∞ –∞—á–∞–∞–ª–∞–≥–¥–ª–∞–∞!")
        except Exception as e:
            messagebox.showerror("–ê–ª–¥–∞–∞", f"–ê—á–∞–∞–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞: {e}")
    
    def show_people_list(self):
        """Show list of registered people"""
        if not self.known_face_names:
            messagebox.showinfo("–ú—ç–¥—ç—ç–ª—ç–ª", "–ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–Ω –±–∞–π—Ö–≥“Ø–π")
            return
        
        name_counts = Counter(self.known_face_names)
        
        message = "üìã –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å:\n\n"
        for name, count in sorted(name_counts.items()):
            message += f"üë§ {name}: {count} –∑—É—Ä–∞–≥\n"
        
        messagebox.showinfo("–ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å", message)
    
    def delete_person(self):
        """Delete a person"""
        if not self.known_face_names:
            messagebox.showinfo("–ú—ç–¥—ç—ç–ª—ç–ª", "–ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–Ω –±–∞–π—Ö–≥“Ø–π")
            return
        
        # Create dialog
        dialog = tk.Toplevel(self.root)
        dialog.title("–•“Ø–Ω —É—Å—Ç–≥–∞—Ö")
        dialog.geometry("400x300")
        dialog.configure(bg='#2d2d44')
        dialog.transient(self.root)
        dialog.grab_set()
        
        tk.Label(
            dialog,
            text="–£—Å—Ç–≥–∞—Ö —Ö“Ø–Ω–∏–π–≥ —Å–æ–Ω–≥–æ–Ω–æ —É—É:",
            font=('Helvetica', 12),
            bg='#2d2d44',
            fg='#ffffff'
        ).pack(pady=20)
        
        name_counts = Counter(self.known_face_names)
        names = sorted(name_counts.keys())
        
        listbox = tk.Listbox(
            dialog,
            font=('Helvetica', 11),
            height=8
        )
        listbox.pack(fill='both', expand=True, padx=20, pady=10)
        
        for name in names:
            listbox.insert(tk.END, f"{name} ({name_counts[name]} –∑—É—Ä–∞–≥)")
        
        def delete_selected():
            selection = listbox.curselection()
            if not selection:
                messagebox.showwarning("–ê–Ω—Ö–∞–∞—Ä—É—É–ª–≥–∞", "–•“Ø–Ω —Å–æ–Ω–≥–æ–Ω–æ —É—É!")
                return
            
            name = names[selection[0]]
            
            indices = [i for i, n in enumerate(self.known_face_names) if n == name]
            for idx in sorted(indices, reverse=True):
                del self.known_face_features[idx]
                del self.known_face_names[idx]
            
            self.update_status(f"üóëÔ∏è {name} —É—Å—Ç–≥–∞–≥–¥–ª–∞–∞!")
            self.save_data()
            self.update_status_display()
            dialog.destroy()
        
        tk.Button(
            dialog,
            text="üóëÔ∏è –£—Å—Ç–≥–∞—Ö",
            command=delete_selected,
            bg='#ff4444',
            fg='#ffffff',
            font=('Helvetica', 11, 'bold'),
            cursor='hand2'
        ).pack(pady=10)


def main():
    root = tk.Tk()
    app = FaceRecognitionGUI(root)
    root.mainloop()


if __name__ == "__main__":
    main()


class FaceRecognitionSystem:
    def __init__(self, threshold=0.82, data_file="face_data.pkl"):
        self.known_face_features = []
        self.known_face_names = []
        self.data_file = data_file
        self.threshold = threshold

        # OpenCV –Ω“Ø“Ø—Ä –æ–ª–æ—Ö classifier
        cascade_path = cv2.data.haarcascades
        self.face_cascade = cv2.CascadeClassifier(
            cascade_path + 'haarcascade_frontalface_default.xml')
        self.eye_cascade = cv2.CascadeClassifier(
            cascade_path + 'haarcascade_eye.xml')

        if self.face_cascade.empty() or self.eye_cascade.empty():
            raise Exception("‚ùå Haar Cascade —Ñ–∞–π–ª—É—É–¥ –∞—á–∞–∞–ª–∞–≥–¥—Å–∞–Ω–≥“Ø–π!")

    def extract_face_features(self, image, face_rect):
        """–ù“Ø“Ø—Ä–Ω–∏–π –æ–Ω—Ü–ª–æ–≥ —à–∏–Ω–∂ —á–∞–Ω–∞—Ä—É—É–¥—ã–≥ –≥–∞—Ä–≥–∞–∂ –∞–≤–∞—Ö"""
        try:
            x, y, w, h = face_rect

            if x < 0 or y < 0 or x+w > image.shape[1] or y+h > image.shape[0]:
                return None

            face = image[y:y+h, x:x+w]

            if face.size == 0:
                return None

            face_resized = cv2.resize(face, (100, 100))

            if len(face_resized.shape) == 3:
                gray_face = cv2.cvtColor(face_resized, cv2.COLOR_BGR2GRAY)
            else:
                gray_face = face_resized

            gray_face = cv2.equalizeHist(gray_face)

            hist = cv2.calcHist([gray_face], [0], None, [256], [0, 256])
            hist = cv2.normalize(hist, hist).flatten()

            lbp_features = self.compute_lbp(gray_face)
            hog_features = self.compute_hog(gray_face)

            features = np.concatenate([hist, lbp_features, hog_features])

            return features
        except Exception as e:
            return None

    def compute_lbp(self, image):
        """Local Binary Pattern features"""
        height, width = image.shape
        radius = 1
        lbp = np.zeros((height-2*radius, width-2*radius), dtype=np.uint8)

        for i in range(radius, height-radius):
            for j in range(radius, width-radius):
                center = image[i, j]
                code = 0
                code |= (image[i-1, j-1] >= center) << 7
                code |= (image[i-1, j] >= center) << 6
                code |= (image[i-1, j+1] >= center) << 5
                code |= (image[i, j+1] >= center) << 4
                code |= (image[i+1, j+1] >= center) << 3
                code |= (image[i+1, j] >= center) << 2
                code |= (image[i+1, j-1] >= center) << 1
                code |= (image[i, j-1] >= center) << 0
                lbp[i-radius, j-radius] = code

        hist_lbp = cv2.calcHist([lbp], [0], None, [256], [0, 256])
        hist_lbp = cv2.normalize(hist_lbp, hist_lbp).flatten()

        return hist_lbp

    def compute_hog(self, image):
        """HOG (Histogram of Oriented Gradients) features"""
        gx = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=1)
        gy = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=1)

        mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)

        bins = np.int32(angle / 40)
        bin_cells = []

        cell_size = 10
        for i in range(0, image.shape[0] - cell_size, cell_size):
            for j in range(0, image.shape[1] - cell_size, cell_size):
                cell_mag = mag[i:i+cell_size, j:j+cell_size]
                cell_angle = bins[i:i+cell_size, j:j+cell_size]

                hist = np.zeros(9)
                for k in range(9):
                    hist[k] = np.sum(cell_mag[cell_angle == k])

                bin_cells.extend(hist)

        hog_features = np.array(bin_cells)
        if np.linalg.norm(hog_features) > 0:
            hog_features = hog_features / np.linalg.norm(hog_features)

        return hog_features[:256]

    def auto_collect_face_data(self, name, num_samples=10, auto_save=True):
        """ü§ñ –ê–í–¢–û–ú–ê–¢ –ù“Æ“Æ–† –¢–ê–ù–ò–£–õ–ê–• - Phone Face ID —à–∏–≥"""

        # –•—ç—Ä—ç–≤ —ç–Ω—ç –Ω—ç—Ä—Ç—ç–π —Ö“Ø–Ω –∞–ª—å —Ö—ç–¥–∏–π–Ω –±–∞–π–≥–∞–∞ –±–æ–ª —Å–∞–Ω—É—É–ª–∞—Ö
        if name in self.known_face_names:
            print(f"‚ö†Ô∏è '{name}' –∞–ª—å —Ö—ç–¥–∏–π–Ω –±“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π –±–∞–π–Ω–∞!")
            choice = input(
                "–Æ—É —Ö–∏–π—Ö –≤—ç?\n  1 - –®–∏–Ω—ç –∑—É—Ä–∞–≥ –ù–≠–ú–≠–• (—Å–∞–π–∂—Ä—É—É–ª–∞—Ö)\n  2 - ”®–º–Ω”©—Ö–∏–π–≥ –°–û–õ–ò–• (—É—Å—Ç–≥–∞–∞–¥ —à–∏–Ω—ç—ç—Ä)\n  3 - –¶—É—Ü–ª–∞—Ö\n–°–æ–Ω–≥–æ–ª—Ç: ").strip()

            if choice == '1':
                print(f"‚úÖ {name}-–¥ —à–∏–Ω—ç –∑—É—Ä–≥—É—É–¥ –Ω—ç–º—ç—Ö –≥–æ—Ä–∏–º–¥ –æ—Ä–ª–æ–æ")
            elif choice == '2':
                indices = [i for i, n in enumerate(
                    self.known_face_names) if n == name]
                for idx in sorted(indices, reverse=True):
                    del self.known_face_features[idx]
                    del self.known_face_names[idx]
                print(f"üóëÔ∏è {name}-—ã–Ω —Ö—É—É—á–∏–Ω –¥–∞—Ç–∞ —É—Å—Ç–≥–∞–≥–¥–ª–∞–∞, —à–∏–Ω—ç—ç—Ä –±“Ø—Ä—Ç–≥—ç–Ω—ç")
            elif choice == '3':
                print("üö´ –¶—É—Ü–ª–∞–≥–¥–ª–∞–∞")
                return False
            else:
                print("‚ùå –ë—É—Ä—É—É —Å–æ–Ω–≥–æ–ª—Ç, —Ü—É—Ü–ª–∞–≥–¥–ª–∞–∞")
                return False

        print(f"\n{'='*60}")
        print(f"üì± {name}-—ã–Ω –Ω“Ø“Ø—Ä–∏–π–≥ –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –±“Ø—Ä—Ç–≥—ç–∂ –±–∞–π–Ω–∞...")
        print(f"üéØ {num_samples} ”©”©—Ä ”©–Ω—Ü–≥”©”©—Å –∑—É—Ä–∞–≥ –∞–≤–Ω–∞")
        print(f"üí° –¢–æ–ª–≥–æ–π–≥–æ–æ –∞–∞–∂—É—É—Ö–∞–Ω —ç—Ä–≥“Ø“Ø–ª—ç—ç—Ä—ç–π")
        print(f"{'='*60}\n")

        video_capture = cv2.VideoCapture(0)

        if not video_capture.isOpened():
            print("‚ùå –ö–∞–º–µ—Ä –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
            return False

        features_list = []
        count = 0
        last_capture_time = time.time()
        capture_interval = 0.5

        face_positions = []
        min_position_diff = 20

        stable_frames = 0
        min_stable_frames = 3

        print("üîç –ù“Ø“Ø—Ä–∏–π–≥ –æ–ª–∂ –±–∞–π–Ω–∞...")

        while count < num_samples:
            ret, frame = video_capture.read()
            if not ret:
                print("‚ùå –ö–∞–º–µ—Ä–∞–∞—Å frame —É–Ω—à–∏–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π!")
                break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.1, minNeighbors=5,
                minSize=(100, 100), maxSize=(400, 400)
            )

            current_time = time.time()
            face_detected = False
            ready_to_capture = False

            for (x, y, w, h) in faces:
                face_detected = True

                roi_gray = gray[y:y+h, x:x+w]
                eyes = self.eye_cascade.detectMultiScale(
                    roi_gray, minNeighbors=8)

                has_eyes = len(eyes) >= 2

                face_center = (x + w//2, y + h//2)

                is_new_angle = True
                for prev_pos in face_positions:
                    distance = np.sqrt((face_center[0] - prev_pos[0])**2 +
                                       (face_center[1] - prev_pos[1])**2)
                    if distance < min_position_diff:
                        is_new_angle = False
                        break

                if has_eyes and is_new_angle:
                    color = (0, 255, 0)
                    stable_frames += 1
                    ready_to_capture = stable_frames >= min_stable_frames
                elif has_eyes:
                    color = (0, 255, 255)
                    stable_frames = 0
                else:
                    color = (0, 165, 255)
                    stable_frames = 0

                thickness = 3 if ready_to_capture else 2
                cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness)

                for (ex, ey, ew, eh) in eyes:
                    cv2.circle(frame, (x+ex+ew//2, y+ey+eh//2),
                               ew//2, (255, 0, 0), 2)

                if (ready_to_capture and is_new_angle and has_eyes and
                        current_time - last_capture_time >= capture_interval):

                    features = self.extract_face_features(frame, (x, y, w, h))

                    if features is not None:
                        features_list.append(features)
                        face_positions.append(face_center)
                        count += 1
                        last_capture_time = current_time
                        stable_frames = 0

                        cv2.circle(
                            frame, (frame.shape[1]//2, frame.shape[0]//2), 50, (0, 255, 0), 5)

                        print(f"üì∏ {count}/{num_samples} - ‚úì –ê–≤–ª–∞–∞!")

            # Progress bar
            bar_width = frame.shape[1] - 40
            bar_height = 30
            bar_x, bar_y = 20, frame.shape[0] - 50

            cv2.rectangle(frame, (bar_x-5, bar_y-5),
                          (bar_x + bar_width + 5, bar_y + bar_height + 5),
                          (50, 50, 50), cv2.FILLED)

            progress = int((count / num_samples) * bar_width)
            cv2.rectangle(frame, (bar_x, bar_y),
                          (bar_x + progress, bar_y + bar_height),
                          (0, 255, 0), cv2.FILLED)

            progress_text = f"{count}/{num_samples}"
            cv2.putText(frame, progress_text,
                        (bar_x + bar_width//2 - 30, bar_y + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            if face_detected:
                if ready_to_capture:
                    status = "üì∏ –ê–≤—á –±–∞–π–Ω–∞..."
                    color = (0, 255, 0)
                elif not has_eyes:
                    status = "üëÄ –ù“Ø–¥–∏–π–≥ —Ö–∞—Ä—É—É–ª–Ω–∞ —É—É"
                    color = (0, 165, 255)
                elif not is_new_angle:
                    status = "üîÑ –¢–æ–ª–≥–æ–π–≥–æ–æ —ç—Ä–≥“Ø“Ø–ª–Ω—ç “Ø“Ø"
                    color = (0, 255, 255)
                else:
                    status = "‚è≥ –ë—ç–ª–¥—ç–∂ –±–∞–π–Ω–∞..."
                    color = (255, 255, 0)
            else:
                status = "üîç –ù“Ø“Ø—Ä–∏–π–≥ –æ–ª–∂ –±–∞–π–Ω–∞..."
                color = (0, 0, 255)

            cv2.putText(frame, status, (20, 40),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

            instruction = "Q - —Ü—É—Ü–ª–∞—Ö | –ê–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –∞–≤–Ω–∞"
            cv2.putText(frame, instruction, (20, 75),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            cv2.imshow('Auto Face ID', frame)

            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\nüö´ –•—ç—Ä—ç–≥–ª—ç–≥—á —Ü—É—Ü–∞–ª—Å–∞–Ω")
                break

        video_capture.release()
        cv2.destroyAllWindows()

        if len(features_list) >= 3:
            for features in features_list:
                self.known_face_features.append(features)
                self.known_face_names.append(name)

            print(f"\n{'='*60}")
            print(f"‚úÖ {name} –∞–º–∂–∏–ª—Ç—Ç–∞–π –±“Ø—Ä—Ç–≥—ç–≥–¥–ª—ç—ç!")
            print(f"üìä {len(features_list)} –∑—É—Ä–∞–≥ —Ö–∞–¥–≥–∞–ª—Å–∞–Ω")
            print(f"{'='*60}\n")

            if auto_save:
                self.save_data()

            return True
        else:
            print(
                f"\n‚ùå –•–∞–Ω–≥–∞–ª—Ç—Ç–∞–π –∑—É—Ä–∞–≥ –∞–≤–∞–∞–≥“Ø–π! ({len(features_list)}/{num_samples})")
            return False

    def collect_face_data_from_images(self, images_folder):
        """–ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä–æ–æ—Å –Ω“Ø“Ø—Ä–∏–π–≥ —Ç–∞–Ω–∏—É–ª–∞—Ö"""
        print(f"üì∏ {images_folder}-–æ–æ—Å –Ω“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∂ –±–∞–π–Ω–∞...")

        if not os.path.exists(images_folder):
            print(f"‚ùå {images_folder} –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False

        image_files = [f for f in os.listdir(images_folder)
                       if f.lower().endswith((".jpg", ".jpeg", ".png", ".bmp"))]

        if not image_files:
            print("‚ùå –ó—É—Ä–∞–≥ –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False

        success_count = 0
        for filename in image_files:
            image_path = os.path.join(images_folder, filename)
            image = cv2.imread(image_path)

            if image is None:
                print(f"‚ö†Ô∏è {filename} —É–Ω—à–∏–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π")
                continue

            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.1, minNeighbors=5,
                minSize=(50, 50), maxSize=(500, 500)
            )

            if len(faces) > 0:
                face = max(faces, key=lambda rect: rect[2] * rect[3])
                features = self.extract_face_features(image, face)

                if features is not None:
                    name = os.path.splitext(
                        filename)[0].replace('_', ' ').title()
                    self.known_face_features.append(features)
                    self.known_face_names.append(name)
                    success_count += 1
                    print(f"‚úÖ {name} —Ç–∞–Ω–∏—É–ª—Å–∞–Ω")
                else:
                    print(f"‚ö†Ô∏è {filename}-–Ω features –≥–∞—Ä–≥–∞–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π")
            else:
                print(f"‚ö†Ô∏è {filename}-–¥ –Ω“Ø“Ø—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π")

        print(f"\nüìä –ù–∏–π—Ç: {success_count}/{len(image_files)} –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏—É–ª—Å–∞–Ω")

        if success_count > 0:
            save = input("\nüíæ –û–¥–æ–æ —Ö–∞–¥–≥–∞–ª–∞—Ö —É—É? (y/n): ").strip().lower()
            if save == 'y' or save == 'yes':
                self.save_data()

        return success_count > 0

    def save_data(self):
        """–ù“Ø“Ø—Ä–Ω–∏–π –¥–∞—Ç–∞–≥ —Ñ–∞–π–ª–¥ —Ö–∞–¥–≥–∞–ª–∞—Ö"""
        try:
            data = {
                'features': self.known_face_features,
                'names': self.known_face_names,
                'threshold': self.threshold,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            with open(self.data_file, 'wb') as f:
                pickle.dump(data, f)

            name_counts = Counter(self.known_face_names)

            print(f"üíæ –î–∞—Ç–∞ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞!")
            print(f"üìÅ –§–∞–π–ª: {self.data_file}")
            print(f"üë• –•“Ø–º“Ø“Ø—Å: {len(name_counts)}")
            print(f"üìä –ù–∏–π—Ç –∑—É—Ä–∞–≥: {len(self.known_face_names)}")
        except Exception as e:
            print(f"‚ùå –•–∞–¥–≥–∞–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}")

    def load_data(self):
        """–•–∞–¥–≥–∞–ª—Å–∞–Ω –¥–∞—Ç–∞–≥ –∞—á–∞–∞–ª–∞—Ö"""
        if not os.path.exists(self.data_file):
            print(f"‚ùå {self.data_file} —Ñ–∞–π–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False

        try:
            with open(self.data_file, 'rb') as f:
                data = pickle.load(f)
                self.known_face_features = data['features']
                self.known_face_names = data['names']

                if 'threshold' in data:
                    self.threshold = data['threshold']

                if 'timestamp' in data:
                    print(f"üìÖ –•–∞–¥–≥–∞–ª—Å–∞–Ω –æ–≥–Ω–æ–æ: {data['timestamp']}")

            name_counts = Counter(self.known_face_names)

            print(f"‚úÖ –î–∞—Ç–∞ –∞—á–∞–∞–ª–∞–≥–¥–ª–∞–∞!")
            print(
                f"üë• –•“Ø–º“Ø“Ø—Å ({len(name_counts)}): {', '.join(sorted(name_counts.keys()))}")
            print(f"üìä –ù–∏–π—Ç –∑—É—Ä–∞–≥: {len(self.known_face_names)}")
            return True
        except Exception as e:
            print(f"‚ùå –ê—á–∞–∞–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}")
            return False

    def compare_faces(self, features1, features2):
        """–•–æ—ë—Ä –Ω“Ø“Ø—Ä–∏–π–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö"""
        cos_sim = np.dot(features1, features2) / (
            np.linalg.norm(features1) * np.linalg.norm(features2) + 1e-6
        )

        euclidean_dist = np.linalg.norm(features1 - features2)
        euclidean_sim = 1 / (1 + euclidean_dist)

        similarity = 0.7 * cos_sim + 0.3 * euclidean_sim
        is_match = similarity > self.threshold

        return similarity, is_match

    def recognize_faces_video(self):
        """–í–∏–¥–µ–æ–≥–æ–æ—Ä –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö"""
        if not self.known_face_features:
            print("‚ùå –≠—Ö–ª—ç—ç–¥ –¥–∞—Ç–∞ –∞—á–∞–∞–ª–Ω–∞ —É—É —ç—Å–≤—ç–ª –Ω“Ø“Ø—Ä —Ç–∞–Ω–∏—É–ª–Ω–∞ —É—É!")
            return

        print(f"\nüé• –ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º —ç—Ö—ç–ª–ª—ç—ç")
        print(f"üë• –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π: {len(set(self.known_face_names))} —Ö“Ø–Ω")
        print(f"üìä –ù–∏–π—Ç –∑—É—Ä–∞–≥: {len(self.known_face_names)}")
        print(f"üéØ Threshold: {self.threshold:.2f}")
        print("Q –¥–∞—Ä–∂ –≥–∞—Ä–Ω–∞ —É—É!\n")

        video_capture = cv2.VideoCapture(0)

        if not video_capture.isOpened():
            print("‚ùå –ö–∞–º–µ—Ä –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
            return

        frame_skip = 3
        frame_count = 0

        fps_start_time = time.time()
        fps_frame_count = 0
        fps = 0

        last_results = {}

        while True:
            ret, frame = video_capture.read()
            if not ret:
                break

            frame_count += 1
            fps_frame_count += 1

            if fps_frame_count >= 30:
                elapsed = time.time() - fps_start_time
                fps = fps_frame_count / elapsed if elapsed > 0 else 0
                fps_start_time = time.time()
                fps_frame_count = 0

            if frame_count % frame_skip != 0:
                for face_id, (x, y, w, h, name, confidence) in last_results.items():
                    if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π":
                        if confidence > 90:
                            color = (0, 255, 0)
                        elif confidence > 85:
                            color = (0, 255, 255)
                        else:
                            color = (0, 165, 255)
                    else:
                        color = (0, 0, 255)

                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)

                    label_y = y - 10 if y - 10 > 10 else y + h + 20
                    cv2.rectangle(frame, (x, label_y - 25),
                                  (x+w, label_y), color, cv2.FILLED)

                    text = f"{name} ({confidence:.0f}%)" if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π" else name
                    cv2.putText(frame, text, (x + 5, label_y - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
                continue

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=1.2, minNeighbors=5,
                minSize=(60, 60), maxSize=(400, 400)
            )

            new_results = {}

            for face_id, (x, y, w, h) in enumerate(faces):
                features = self.extract_face_features(frame, (x, y, w, h))

                if features is None:
                    continue

                name = "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π"
                confidence = 0

                max_similarity = 0
                best_match_name = None

                for idx, known_features in enumerate(self.known_face_features):
                    similarity, _ = self.compare_faces(
                        known_features, features)
                    if similarity > max_similarity:
                        max_similarity = similarity
                        best_match_name = self.known_face_names[idx]

                if max_similarity > self.threshold and best_match_name:
                    name = best_match_name
                    confidence = max_similarity * 100

                new_results[face_id] = (x, y, w, h, name, confidence)

                if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π":
                    if confidence > 90:
                        color = (0, 255, 0)
                    elif confidence > 85:
                        color = (0, 255, 255)
                    else:
                        color = (0, 165, 255)
                else:
                    color = (0, 0, 255)

                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)

                label_y = y - 10 if y - 10 > 10 else y + h + 20
                cv2.rectangle(frame, (x, label_y - 25),
                              (x+w, label_y), color, cv2.FILLED)

                text = f"{name} ({confidence:.0f}%)" if name != "–¢–∞–Ω–∏–≥–¥–∞–∞–≥“Ø–π" else name
                cv2.putText(frame, text, (x + 5, label_y - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            last_results = new_results

            cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            cv2.putText(frame, f"–ù“Ø“Ø—Ä: {len(faces)}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            cv2.imshow('–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º', frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        video_capture.release()
        cv2.destroyAllWindows()
        print("\nüëã –°–∏—Å—Ç–µ–º —Ö–∞–∞–≥–¥–ª–∞–∞")

    def delete_person(self, name):
        """–•“Ø–Ω–∏–π –¥–∞—Ç–∞–≥ —É—Å—Ç–≥–∞—Ö"""
        indices_to_remove = [i for i, n in enumerate(
            self.known_face_names) if n == name]

        if not indices_to_remove:
            print(f"‚ùå {name} –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
            return False

        for idx in sorted(indices_to_remove, reverse=True):
            del self.known_face_features[idx]
            del self.known_face_names[idx]

        print(f"‚úÖ {name} ({len(indices_to_remove)} –∑—É—Ä–∞–≥) —É—Å—Ç–≥–∞–≥–¥–ª–∞–∞!")
        return True

    def list_people(self):
        """–ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö"""
        if not self.known_face_names:
            print("üìã –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–Ω –±–∞–π—Ö–≥“Ø–π")
            return

        name_counts = Counter(self.known_face_names)

        print(f"\nüìã –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å ({len(name_counts)}):")
        print("=" * 50)
        for name, count in sorted(name_counts.items()):
            print(f"  üë§ {name}: {count} –∑—É—Ä–∞–≥")
        print("=" * 50)


def main():
    # –≠–Ω–≥–∏–π–Ω —Ñ–∞–π–ª—ã–Ω –Ω—ç—Ä –∞—à–∏–≥–ª–∞—Ö - –æ–¥–æ–æ–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä—Ç —Ö–∞–¥–≥–∞–ª–Ω–∞
    system = FaceRecognitionSystem(
        threshold=0.72, data_file="C:/Users/troyz/OneDrive/Desktop/faceless/data/face_data.pkl")

    print("=" * 60)
    print("üì± AUTO FACE ID –°–ò–°–¢–ï–ú (Phone Face ID —à–∏–≥)")
    print("=" * 60)

    # ”®–º–Ω”©—Ö –¥–∞—Ç–∞ –±–∞–π–≤–∞–ª –∞—á–∞–∞–ª–∞—Ö
    if os.path.exists(system.data_file):
        print("\nüìÇ ”®–º–Ω”©—Ö –¥–∞—Ç–∞ –æ–ª–¥–ª–æ–æ, –∞—á–∞–∞–ª–∂ –±–∞–π–Ω–∞...")
        system.load_data()
    else:
        print("\nüìù –®–∏–Ω—ç —ç—Ö–ª—ç–ª - –æ–¥–æ–æ–≥–æ–æ—Ä —Ö–∞–¥–≥–∞–ª—Å–∞–Ω –¥–∞—Ç–∞ –±–∞–π—Ö–≥“Ø–π")

    while True:
        print("\nüìã “Æ–ô–õ –ê–ñ–ò–õ–õ–ê–ì–ê–ê:")
        print("  1 - ü§ñ –ê–í–¢–û–ú–ê–¢ –Ω“Ø“Ø—Ä –±“Ø—Ä—Ç–≥—ç—Ö (Space –¥–∞—Ä–∞—Ö —à–∞–∞—Ä–¥–ª–∞–≥–∞–≥“Ø–π)")
        print("  2 - –ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä–æ–æ—Å –¥–∞—Ç–∞ —Ü—É–≥–ª—É—É–ª–∞—Ö")
        print("  3 - –î–∞—Ç–∞–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö (–≥–∞—Ä–∞–∞—Ä)")
        print("  4 - –î–∞—Ç–∞–≥ –¥–∞—Ö–∏–Ω –∞—á–∞–∞–ª–∞—Ö")
        print("  5 - –í–∏–¥–µ–æ–≥–æ–æ—Ä —Ç–∞–Ω–∏–ª—Ç —Ö–∏–π—Ö")
        print("  6 - –ë“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å–∏–π–≥ —Ö–∞—Ä–∞—Ö")
        print("  7 - –•“Ø–Ω–∏–π –¥–∞—Ç–∞–≥ —É—Å—Ç–≥–∞—Ö")
        print(
            "  8 - Threshold —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö (–æ–¥–æ–æ: {:.2f})".format(system.threshold))
        print("  9 - –ë“Ø—Ö –¥–∞—Ç–∞–≥ —É—Å—Ç–≥–∞—Ö (reset)")
        print("  0 - –ì–∞—Ä–∞—Ö")
        print("-" * 60)
        if system.known_face_names:
            print(
                f"üíæ –û–¥–æ–æ–≥–∏–π–Ω –¥–∞—Ç–∞: {len(set(system.known_face_names))} —Ö“Ø–Ω –±“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π")
        else:
            print("‚ö†Ô∏è –û–¥–æ–æ–≥–æ–æ—Ä –±“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–Ω –±–∞–π—Ö–≥“Ø–π")
        print("-" * 60)

        choice = input("–°–æ–Ω–≥–æ–ª—Ç: ").strip()

        if choice == '1':
            if system.known_face_names:
                print("\nüìã –û–¥–æ–æ –±“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å:")
                unique_names = sorted(set(system.known_face_names))
                for i, person in enumerate(unique_names, 1):
                    count = system.known_face_names.count(person)
                    print(f"  {i}. {person} ({count} –∑—É—Ä–∞–≥)")
                print()

            name = input("–•“Ø–Ω–∏–π –Ω—ç—Ä: ").strip()
            if name:
                num = input(
                    "–•—ç–¥—ç–Ω ”©–Ω—Ü–≥”©”©—Å –∞–≤–∞—Ö –≤—ç? (5-15, default=10): ").strip()
                num = int(num) if num.isdigit() else 10
                system.auto_collect_face_data(name, num, auto_save=True)
            else:
                print("‚ùå –ù—ç—Ä –æ—Ä—É—É–ª–Ω–∞ —É—É!")

        elif choice == '2':
            if system.known_face_names:
                print("\nüìã –û–¥–æ–æ –±“Ø—Ä—Ç–≥—ç–ª—Ç—ç–π —Ö“Ø–º“Ø“Ø—Å:")
                unique_names = sorted(set(system.known_face_names))
                for i, person in enumerate(unique_names, 1):
                    count = system.known_face_names.count(person)
                    print(f"  {i}. {person} ({count} –∑—É—Ä–∞–≥)")
                print()

            folder = input("–ó—É—Ä–≥–∏–π–Ω —Ñ–æ–ª–¥–µ—Ä—ã–Ω –∑–∞–º: ").strip()
            if folder:
                system.collect_face_data_from_images(folder)
            else:
                print("‚ùå –§–æ–ª–¥–µ—Ä—ã–Ω –∑–∞–º –æ—Ä—É—É–ª–Ω–∞ —É—É!")

        elif choice == '3':
            if system.known_face_features:
                system.save_data()
            else:
                print("‚ùå –•–∞–¥–≥–∞–ª–∞—Ö –¥–∞—Ç–∞ –±–∞–π—Ö–≥“Ø–π!")

        elif choice == '4':
            system.load_data()

        elif choice == '5':
            system.recognize_faces_video()

        elif choice == '6':
            system.list_people()

        elif choice == '7':
            system.list_people()
            if system.known_face_names:
                name = input("\n–£—Å—Ç–≥–∞—Ö —Ö“Ø–Ω–∏–π –Ω—ç—Ä: ").strip()
                if name and system.delete_person(name):
                    save = input(
                        "üíæ ”®”©—Ä—á–ª”©–ª—Ç–∏–π–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö —É—É? (y/n): ").strip().lower()
                    if save == 'y' or save == 'yes':
                        system.save_data()

        elif choice == '8':
            try:
                new_threshold = float(
                    input(f"–®–∏–Ω—ç threshold (0.7-0.95, –æ–¥–æ–æ={system.threshold:.2f}): "))
                if 0.7 <= new_threshold <= 0.95:
                    system.threshold = new_threshold
                    print(
                        f"‚úÖ Threshold {new_threshold:.2f} –±–æ–ª–≥–æ–∂ ”©”©—Ä—á–ª”©–≥–¥–ª”©”©")
                else:
                    print("‚ùå 0.7-0.95 —Ö–æ–æ—Ä–æ–Ω–¥ —É—Ç–≥–∞ –æ—Ä—É—É–ª–Ω–∞ —É—É!")
            except ValueError:
                print("‚ùå –ë—É—Ä—É—É —É—Ç–≥–∞!")

        elif choice == '9':
            confirm = input(
                "‚ö†Ô∏è –ë“Æ–• –î–ê–¢–ê–ì –£–°–¢–ì–ê–• —É—É? –ë—É—Ü–∞–∞—Ö –±–æ–ª–æ–º–∂–≥“Ø–π! (yes –≥—ç–∂ –±–∏—á–Ω—ç “Ø“Ø): ").strip()
            if confirm.lower() == 'yes':
                system.known_face_features = []
                system.known_face_names = []
                if os.path.exists(system.data_file):
                    os.remove(system.data_file)
                    print("‚úÖ –ë“Ø—Ö –¥–∞—Ç–∞ —É—Å—Ç–≥–∞–≥–¥–ª–∞–∞!")
                else:
                    print("‚úÖ RAM –¥–∞—Ö—å –¥–∞—Ç–∞ —Ü—ç–≤—ç—Ä–ª—ç–≥–¥–ª—ç—ç!")
            else:
                print("üö´ –¶—É—Ü–ª–∞–≥–¥–ª–∞–∞")

        elif choice == '0':
            # –ì–∞—Ä–∞—Ö—ã–Ω ”©–º–Ω”© —Ö–∞–¥–≥–∞–ª–∞–∞–≥“Ø–π ”©”©—Ä—á–ª”©–ª—Ç –±–∞–π–≤–∞–ª —Å–∞–Ω—É—É–ª–∞—Ö
            if system.known_face_features:
                needs_save = True
                if os.path.exists(system.data_file):
                    try:
                        with open(system.data_file, 'rb') as f:
                            saved_data = pickle.load(f)
                            if (len(saved_data['names']) == len(system.known_face_names) and
                                    saved_data['names'] == system.known_face_names):
                                needs_save = False
                    except:
                        needs_save = True

                if needs_save:
                    save_prompt = input(
                        "\n‚ö†Ô∏è –•–∞–¥–≥–∞–ª–∞–∞–≥“Ø–π ”©”©—Ä—á–ª”©–ª—Ç –±–∞–π–Ω–∞! –•–∞–¥–≥–∞–ª–∞—Ö —É—É? (y/n): ").strip().lower()
                    if save_prompt == 'y' or save_prompt == 'yes':
                        system.save_data()

            print("\n" + "=" * 60)
            print("üëã –ë–∞—è—Ä—Ç–∞–π! –ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º —Ö–∞–∞–≥–¥–∞–∂ –±–∞–π–Ω–∞...")
            print("=" * 60)
            break

        else:
            print("‚ùå –ë—É—Ä—É—É —Å–æ–Ω–≥–æ–ª—Ç! –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüõë –ü—Ä–æ–≥—Ä–∞–º –∑–æ–≥—Å—Å–æ–Ω (Ctrl+C)")
    except Exception as e:
        print(f"\n‚ùå –ê–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}")
  